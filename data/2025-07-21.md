<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 5]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence](https://arxiv.org/abs/2507.13481)
*Arthur Bueno,Bruno Cafeo,Maria Cagnin,Awdren Fontão*

Main category: cs.SE

TL;DR: 研究探讨开源生态系统中代码样本的技术异味（如大类、模块化差）与社区异味（如孤立贡献者、沟通碎片化）如何共同出现并随时间演变，发现社区问题常预示或加剧技术退化。


<details>
  <summary>Details</summary>
Motivation: 代码样本在开源生态中虽重要但管理松散，技术与社会问题交织影响其质量，需探究其动态关系。

Method: 采用多声文献综述法，分析30篇学术论文和17篇实践导向资料（2013-2024），主题合成识别异味动态模式。

Result: 发现9种模式，社区异味常先于或强化技术退化，如“无线电静默”和集中所有权与结构问题相关。

Conclusion: 社区功能障碍预示可维护性下降，需针对共享教学工具体制轻量级治理机制。

Abstract: Code samples play a pivotal role in open-source ecosystems (OSSECO), serving
as lightweight artifacts that support knowledge transfer, onboarding, and
framework adoption. Despite their instructional relevance, these samples are
often governed informally, with minimal review and unclear ownership, which
increases their exposure to socio-technical degradation. In this context, the
co-occurrence and longitudinal interplay of code smells (e.g., large classes,
poor modularity) and community smells (e.g., lone contributors, fragmented
communication) become particularly critical. While each type of smell has been
studied in isolation, little is known about how community-level dysfunctions
anticipate or exacerbate technical anomalies in code samples over time. This
study investigates how code and community smells emerge, co-occur, and evolve
within code samples maintained in OSSECOs. A Multivocal Literature Review
protocol was applied, encompassing 30 peer-reviewed papers and 17
practitioner-oriented sources (2013-2024). Thematic synthesis was conducted to
identify recurring socio-technical patterns related to smell dynamics. Nine
patterns were identified, showing that community smells often precede or
reinforce technical degradation in code samples. Symptoms such as "radio
silence" and centralized ownership were frequently associated with persistent
structural anomalies. Additionally, limited onboarding, the absence of
continuous refactoring, and informal collaboration emerged as recurring
conditions for smell accumulation. Conclusion: In OSSECOs, particularly within
code samples, community-level dysfunctions not only correlate with but often
signal maintainability decay. These findings underscore the need for
socio-technical quality indicators and lightweight governance mechanisms
tailored to shared instructional artifacts.

</details>


### [2] [AI-Assisted Fixes to Code Review Comments at Scale](https://arxiv.org/abs/2507.13499)
*Chandra Maddila,Negar Ghorbani,James Saindon,Parth Thakkar,Vijayaraghavan Murali,Rui Abreu,Jingyue Shen,Brian Zhou,Nachiappan Nagappan,Peter C. Rigby*

Main category: cs.SE

TL;DR: Meta开发了MetaMateCR，通过AI辅助修复代码审查意见，并在生产中大规模应用。通过微调Llama模型，其表现优于GPT-4o，同时通过安全试验确保不影响审查效率。


<details>
  <summary>Details</summary>
Motivation: 解决Meta每周数万条代码审查意见的处理问题，提高效率。

Method: 使用64k数据点微调Llama模型，进行离线测试和安全试验后投入生产。

Result: LargeLSFT模型离线测试中准确率68%，优于GPT-4o 9个百分点；生产中应用率19.7%，提升9.2个百分点。

Conclusion: MetaMateCR成功展示了AI辅助修复代码审查意见的潜力，同时强调了安全试验的重要性。

Abstract: Aim. There are 10s of thousands of code review comments each week at Meta. We
developed Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes
for reviewer comments in production at scale.
  Method. We developed an internal benchmark of 64k <review comment, patch>
data points to fine-tune Llama models. Once our models achieve reasonable
offline results, we roll them into production. To ensure that our AI-assisted
fixes do not negatively impact the time it takes to do code reviews, we conduct
randomized controlled safety trials as well as full production experiments.
  Offline Results. As a baseline, we compare GPT-4o to our small and large
Llama models. In offline results, our LargeLSFT model creates an exact match
patch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The
internal models also use more modern Hack functions when compared to the PHP
functions suggested by GPT-4o.
  Safety Trial. When we roll MetaMateCR into production in a safety trial that
compares no AI patches with AI patch suggestions, we see a large regression
with reviewers taking over 5% longer to conduct reviews. After investigation,
we modify the UX to only show authors the AI patches, and see no regressions in
the time for reviews.
  Production. When we roll LargeLSFT into production, we see an
ActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.
Our results illustrate the importance of safety trials in ensuring that AI does
not inadvertently slow down engineers, and a successful review comment to AI
patch product running at scale.

</details>


### [3] [Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software](https://arxiv.org/abs/2507.13553)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: 研究探讨了开源软件中功能请求的模糊性和不完整性，以及开发者澄清问题的动态过程，发现澄清行为较少，且更关注用户意图而非技术细节。


<details>
  <summary>Details</summary>
Motivation: 功能请求常因自然语言表达模糊或不完整导致误解，影响软件质量，但开发者澄清过程的实践尚不明确。

Method: 通过分析开源软件平台上的功能请求和开发者澄清对话，研究其动态和模式。

Result: 功能请求普遍存在模糊性和不完整性，开发者较少明确澄清，更注重项目目标和用户意图。

Conclusion: 研究揭示了澄清行为的模式，有助于改进用户与开发者的协作，优化功能请求处理实践。

Abstract: As user demands evolve, effectively incorporating feature requests is crucial
for maintaining software relevance and user satisfaction. Feature requests,
typically expressed in natural language, often suffer from ambiguity or
incomplete information due to communication gaps or the requester's limited
technical expertise. These issues can lead to misinterpretation, faulty
implementation, and reduced software quality. While seeking clarification from
requesters is a common strategy to mitigate these risks, little is known about
how developers engage in this clarification process in practice-how they
formulate clarifying questions, seek technical or contextual details, align on
goals and use cases, or decide to close requests without attempting
clarification. This study investigates how feature requests are prone to NL
defects (i.e. ambiguous or incomplete) and the conversational dynamics of
clarification in open-source software (OSS) development, aiming to understand
how developers handle ambiguous or incomplete feature requests. Our findings
suggest that feature requests published on the OSS platforms do possess
ambiguity and incompleteness, and in some cases, both. We also find that
explicit clarification for the resolution of these defects is uncommon;
developers usually focus on aligning with project goals rather than resolving
unclear text. When clarification occurs, it emphasizes understanding user
intent/goal and feasibility, rather than technical details. By characterizing
the dynamics of clarification in open-source issue trackers, this work
identifies patterns that can improve user-developer collaboration and inform
best practices for handling feature requests effectively.

</details>


### [4] [Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software](https://arxiv.org/abs/2507.13555)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: 本文提出了一种利用大型语言模型（LLMs）自动检测和优化自然语言（NL）缺陷的方法，以提高开源软件（OSS）中功能请求的清晰度。


<details>
  <summary>Details</summary>
Motivation: 软件应用需求快速增长，但用户提供的功能请求常因模糊和不完整而难以处理，传统验证方法在分散环境中不适用。

Method: 利用LLMs自动识别模糊和不完整的请求，并生成澄清问题（CQs）以改进请求。

Result: 方法在真实OSS功能请求上验证，并与人工标注对比，同时通过开发者访谈了解NL缺陷的影响。

Conclusion: 该方法有效提升了功能请求的清晰度，为开发者提供了实用工具。

Abstract: The growing popularity and widespread use of software applications (apps)
across various domains have driven rapid industry growth. Along with this
growth, fast-paced market changes have led to constantly evolving software
requirements. Such requirements are often grounded in feature requests and
enhancement suggestions, typically provided by users in natural language (NL).
However, these requests often suffer from defects such as ambiguity and
incompleteness, making them challenging to interpret. Traditional validation
methods (e.g., interviews and workshops) help clarify such defects but are
impractical in decentralized environments like open-source software (OSS),
where change requests originate from diverse users on platforms like GitHub.
This paper proposes a novel approach leveraging Large Language Models (LLMs) to
detect and refine NL defects in feature requests. Our approach automates the
identification of ambiguous and incomplete requests and generates clarification
questions (CQs) to enhance their usefulness for developers. To evaluate its
effectiveness, we apply our method to real-world OSS feature requests and
compare its performance against human annotations. In addition, we conduct
interviews with GitHub developers to gain deeper insights into their
perceptions of NL defects, the strategies they use to address these defects,
and the impact of defects on downstream software engineering (SE) tasks.

</details>


### [5] [Testing Autonomous Driving Systems -- What Really Matters and What Doesn't](https://arxiv.org/abs/2507.13661)
*Changwen Li,Joseph Sifakis,Rongjie Yan,Jian Zhang*

Main category: cs.SE

TL;DR: 本文探讨了自动驾驶系统（ADS）测试方法的有效性和有效性验证问题，指出当前方法存在不足，并提出改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统的测试方法缺乏统一标准，无法准确评估其重要性和贡献。本文旨在解决这一问题。

Method: 提出一个比较测试方法的框架，分析其有效性和有效性验证，并研究测试结果与自动驾驶设计的关系。

Result: 发现许多测试方法未能满足有效性和有效性验证要求，且测试结果高度依赖于自动驾驶的设计方式。

Conclusion: 当前技术下无法对自动驾驶核心属性提供足够保证，建议开发时注重合理性和确定性。

Abstract: Despite extensive research, the testing of autonomous driving systems (ADS)
landscape remains fragmented, and there is currently no basis for an informed
technical assessment of the importance and contribution of the current state of
the art. This paper attempts to address this problem by exploring two
complementary aspects.
  First, it proposes a framework for comparing existing test methods in terms
of their intrinsic effectiveness and validity. It shows that many methods do
not meet both of these requirements. Either because they are based on criteria
that do not allow for rapid, inexpensive, and comprehensive detection of
failures, or because the degree of validity of the properties tested cannot be
accurately estimated. In particular, it is shown that most critical test
methods do not take into account the nominal operational capabilities of
autopilots and generate scenarios that are impossible for the tested vehicles
to handle, resulting in unjustified rejections.
  Secondly, the paper shows that test effectiveness and validity are highly
dependent on how autopilots are designed: how they choose between different
control policies to perform maneuvers, as well as on the reproducibility of the
results. In fact, most test methods take for granted two principles underlying
traditional methods, but do not generally apply to ADS. We maintain that the
absence of rationality and determinacy significantly impairs the effectiveness
and validity of test methods, and provide test results on eight open
autopilots, in which most do not satisfy these properties, thereby illustrating
this fact.
  We conclude that under the current state of the art, it is impossible to
obtain strong enough guarantees for essential autopilot properties and
recommend that autopilots be developed with a view to both rationality and
determinacy.

</details>
