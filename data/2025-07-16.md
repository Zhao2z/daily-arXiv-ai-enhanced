<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 20]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [$\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection](https://arxiv.org/abs/2507.10583)
*Daniil Orel,Indraneil Paul,Iryna Gurevych,Preslav Nakov*

Main category: cs.SE

TL;DR: 论文介绍了$	exttt{DroidCollection}$，一个包含百万代码样本、七种编程语言和43种编码模型输出的开放数据集，用于训练和评估机器生成代码检测器。同时提出了$	exttt{DroidDetect}$检测器套件，通过多任务目标训练，解决了现有检测器在多样化场景中的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器生成代码检测器在多样化编程语言和领域中的泛化能力不足，且易受对抗性样本攻击。

Method: 构建$	exttt{DroidCollection}$数据集，并开发$	exttt{DroidDetect}$检测器套件，采用多任务目标和对抗性数据训练。

Result: 实验表明$	exttt{DroidDetect}$在多样化场景中表现优于现有检测器，且对抗性训练能有效提升鲁棒性。

Conclusion: $	exttt{DroidCollection}$和$	exttt{DroidDetect}$为机器生成代码检测提供了更全面的数据集和解决方案。

Abstract: In this work, we compile $\textbf{$\texttt{DroidCollection}$}$, the most
extensive open data suite for training and evaluating machine-generated code
detectors, comprising over a million code samples, seven programming languages,
outputs from 43 coding models, and over three real-world coding domains.
Alongside fully AI-generated samples, our collection includes human-AI
co-authored code, as well as adversarial samples explicitly crafted to evade
detection. Subsequently, we develop $\textbf{$\texttt{DroidDetect}$}$, a suite
of encoder-only detectors trained using a multi-task objective over
$\texttt{DroidCollection}$. Our experiments show that existing detectors'
performance fails to generalise to diverse coding domains and programming
languages outside of their narrow training data. Additionally, we demonstrate
that while most detectors are easily compromised by humanising the output
distributions using superficial prompting and alignment approaches, this
problem can be easily amended by training on a small amount of adversarial
data. Finally, we demonstrate the effectiveness of metric learning and
uncertainty-based resampling as means to enhance detector training on possibly
noisy distributions.

</details>


### [2] [ARPaCCino: An Agentic-RAG for Policy as Code Compliance](https://arxiv.org/abs/2507.10584)
*Francesco Romeo,Luigi Arena,Francesco Blefari,Francesco Aurelio Pironti,Matteo Lupinacci,Angelo Furfaro*

Main category: cs.SE

TL;DR: ARPaCCino是一个结合LLMs、RAG和工具验证的系统，用于自动化生成和验证Policy as Code规则，提升IaC环境中的合规性。


<details>
  <summary>Details</summary>
Motivation: Policy as Code的采用受限于复杂的策略语言和配置错误风险，ARPaCCino旨在解决这些问题。

Method: 利用LLMs、RAG和工具验证，从自然语言描述生成Rego规则，并验证和优化IaC配置。

Result: 实验证明ARPaCCino能生成正确策略，识别不合规基础设施，并进行修正，即使使用小型LLMs。

Conclusion: ARPaCCino展示了基于RAG的智能架构在提升PaC自动化、可靠性和可访问性方面的潜力。

Abstract: Policy as Code (PaC) is a paradigm that encodes security and compliance
policies into machine-readable formats, enabling automated enforcement in
Infrastructure as Code (IaC) environments. However, its adoption is hindered by
the complexity of policy languages and the risk of misconfigurations. In this
work, we present ARPaCCino, an agentic system that combines Large Language
Models (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation
to automate the generation and verification of PaC rules. Given natural
language descriptions of the desired policies, ARPaCCino generates formal Rego
rules, assesses IaC compliance, and iteratively refines the IaC configurations
to ensure conformance. Thanks to its modular agentic architecture and
integration with external tools and knowledge bases, ARPaCCino supports policy
validation across a wide range of technologies, including niche or emerging IaC
frameworks. Experimental evaluation involving a Terraform-based case study
demonstrates ARPaCCino's effectiveness in generating syntactically and
semantically correct policies, identifying non-compliant infrastructures, and
applying corrective modifications, even when using smaller, open-weight LLMs.
Our results highlight the potential of agentic RAG architectures to enhance the
automation, reliability, and accessibility of PaC workflows.

</details>


### [3] [Repairing Language Model Pipelines by Meta Self-Refining Competing Constraints at Runtime](https://arxiv.org/abs/2507.10590)
*Mojtaba Eshghie*

Main category: cs.SE

TL;DR: Meta Self-Refining框架通过元修正层修复语言模型管道中的竞争约束问题，提高效率。


<details>
  <summary>Details</summary>
Motivation: 语言模型管道在竞争软约束下效率低下，需动态修复。

Method: 引入元修正层，监测执行历史并调用元修复器LM合成策略指令。

Result: 成功修复循环，提升语言模型程序效率。

Conclusion: Meta Self-Refining有效解决竞争约束问题，优化语言模型输出。

Abstract: Language Model (LM) pipelines can dynamically refine their outputs against
programmatic constraints. However, their effectiveness collapses when faced
with competing soft constraints, leading to inefficient backtracking loops
where satisfying one constraint violates another. We introduce Meta
Self-Refining, a framework that equips LM pipelines with a meta-corrective
layer to repair these competitions at runtime/inference-time. Our approach
monitors the pipeline's execution history to detect oscillatory failures. Upon
detection, it invokes a meta-repairer LM that analyzes the holistic state of
the backtracking attempts and synthesizes a strategic instruction to balance
the competing requirements. This self-repair instruction guides the original LM
out of a failing refining loop towards a successful output. Our results show
Meta Self-Refining can successfully repair these loops, leading to more
efficient LM programs.

</details>


### [4] [ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs](https://arxiv.org/abs/2507.10593)
*Peng Ding*

Main category: cs.SE

TL;DR: Toolregistry是一个协议无关的工具管理库，通过统一接口简化工具注册、表示、执行和生命周期管理，显著减少集成代码并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）应用的工具集成方法存在碎片化、协议限制和实现复杂性问题，导致开发成本高。

Method: 提出Toolregistry，一个协议无关的工具管理库，提供统一接口管理工具。

Result: Toolregistry减少60-80%的集成代码，性能提升3.1倍，100%兼容OpenAI函数调用标准。

Conclusion: Toolregistry显著提升开发效率和代码可维护性，已在真实场景中验证效果。

Abstract: Large Language Model (LLM) applications are increasingly relying on external
tools to extend their capabilities beyond text generation. However, current
tool integration approaches suffer from fragmentation, protocol limitations,
and implementation complexity, leading to substantial development overhead.
This paper presents Toolregistry, a protocol-agnostic tool management library
that simplifies tool registration, representation, execution, and lifecycle
management via a unified interface. Our evaluation demonstrates that
\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x
performance improvements through concurrent execution, and 100% compatibility
with OpenAI function calling standards. Real-world case studies show
significant improvements in development efficiency and code maintainability
across diverse integration scenarios. \toolregistry is open-source and
available at https://github.com/Oaklight/ToolRegistry, with comprehensive
documentation at https://toolregistry.readthedocs.io/.

</details>


### [5] [SENSOR: An ML-Enhanced Online Annotation Tool to Uncover Privacy Concerns from User Reviews in Social-Media Applications](https://arxiv.org/abs/2507.10640)
*Labiba Farah,Mohammad Ridwan Kabir,Shohel Ahmed,MD Mohaymen Ul Anam,Md. Sakibul Islam*

Main category: cs.SE

TL;DR: 论文提出SENSOR工具和GRACE模型，用于自动分类用户评论中的隐私相关请求和问题，提升开发者处理隐私问题的效率。


<details>
  <summary>Details</summary>
Motivation: 社交媒体的隐私问题日益突出，用户评论中大量隐私相关反馈难以手动处理，现有工具缺乏对隐私相关请求和问题的专门分类。

Method: 提出GRACE模型（基于GRU、CBOW和注意力机制）和SENSOR工具，分析16000条用户评论，通过高一致性标注训练模型。

Result: GRACE模型表现最佳（F1分数0.9434，ROC-AUC 0.9934，准确率95.10%），能有效分类隐私相关评论。

Conclusion: SENSOR工具和GRACE模型能显著帮助开发者提取和处理隐私相关反馈，提升用户隐私保护。

Abstract: The widespread use of social media applications has raised significant
privacy concerns, often highlighted in user reviews. These reviews also provide
developers with valuable insights into improving apps by addressing issues and
introducing better features. However, the sheer volume and nuanced nature of
reviews make manual identification and prioritization of privacy-related
concerns challenging for developers. Previous studies have developed software
utilities to automatically classify user reviews as privacy-relevant,
privacy-irrelevant, bug reports, feature requests, etc., using machine
learning. Notably, there is a lack of focus on classifying reviews specifically
as privacy-related feature requests, privacy-related bug reports, or
privacy-irrelevant. This paper introduces SENtinel SORt (SENSOR), an automated
online annotation tool designed to help developers annotate and classify user
reviews into these categories. For automating the annotation of such reviews,
this paper introduces the annotation model, GRACE (GRU-based Attention with
CBOW Embedding), using Gated Recurrent Units (GRU) with Continuous Bag of Words
(CBOW) and Attention mechanism. Approximately 16000 user reviews from seven
popular social media apps on Google Play Store, including Instagram, Facebook,
WhatsApp, Snapchat, X (formerly Twitter), Facebook Lite, and Line were
analyzed. Two annotators manually labelled the reviews, achieving a Cohen's
Kappa value of 0.87, ensuring a labeled dataset with high inter-rater agreement
for training machine learning models. Among the models tested, GRACE
demonstrated the best performance (macro F1-score: 0.9434, macro ROC-AUC:
0.9934, and accuracy: 95.10%) despite class imbalance. SENSOR demonstrates
significant potential to assist developers with extracting and addressing
privacy-related feature requests or bug reports from user reviews, enhancing
user privacy and trust.

</details>


### [6] [A Code Comprehension Benchmark for Large Language Models for Code](https://arxiv.org/abs/2507.10641)
*Jayant Havare,Saurav Chaudhary,Ganesh Ramakrishnan,Kaushik Maharajan,Srikanth Tamilselvam*

Main category: cs.SE

TL;DR: 论文探讨了大语言模型在代码任务中的表现，提出通过微调提升代码理解能力，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在代码生成等任务中表现优异，但缺乏深层次语义理解能力，导致在调试和优化等任务中表现不佳。

Method: 通过在大规模数据集上微调模型，专门针对代码理解任务进行优化。

Result: 实验显示微调后模型性能显著提升，尤其是QWQ-32B模型准确率从70%提高到83.47%，Codestral-22B模型在主观评分任务中达到87.66%的准确率。

Conclusion: 微调能有效提升大语言模型的代码理解能力，尤其在需要语义理解的任务中表现更优。

Abstract: Large Language Models have shown impressive capabilities in coding tasks like
code generation and code completion, as they have been trained on a large
amount of code data. Also, since one of the core pretraining objectives is Next
Token Prediction, these models tends to learn surface-level syntactic patterns
in code. However, this does not guarantee code comprehension ability i.e. the
ability to capture the semantics of the code. In our opinion, this is the
reason why these models often underperform on tasks that require deeper
semantic understanding, such as code debugging and code optimization. To
address this, we propose fine-tuning these models specifically for code
comprehension tasks using large-scale datasets, enabling them to develop a more
robust understanding of code semantics. We evaluate three code models of
varying sizes on a suite of code comprehension tasks designed to assess
semantic understanding beyond surface-level syntactic pattern matching. In
particular, we analyze performance on the Subjectivity Grading Task and observe
that model performance improves after fine-tuning on relevant downstream tasks.
The most significant improvement is seen in the QWQ-32B model, where accuracy
increases from 70% to 83.47%. A similar or explainable trend is observed across
other models, clearly indicating an enhancement in code comprehension ability.
Among the models studied, the DPO-fine-tuned Codestral-22B achieves the highest
micro-accuracy of 87.66% on the Subjectivity Grading Task.

</details>


### [7] [CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance](https://arxiv.org/abs/2507.10646)
*Myeongsoo Kim,Shweta Garg,Baishakhi Ray,Varun Kumar,Anoop Deoras*

Main category: cs.SE

TL;DR: CodeAssistBench (CAB) 是一个评估多轮编程辅助的基准框架，针对真实代码库中的问题，揭示了现有大语言模型在复杂项目环境中的能力差距。


<details>
  <summary>Details</summary>
Motivation: 现有的编程助手基准主要关注代码生成任务，缺乏对多轮交互和真实项目环境的评估。CAB 旨在填补这一空白。

Method: CAB 通过从 GitHub 问题自动生成可扩展的数据集，并利用容器化代码库和模拟用户进行评估。

Result: 测试集包含 3,286 个真实编程问题，评估显示模型在 Stack Overflow 上表现良好（70-83%），但在 CAB 的复杂问题上成功率仅 16.49%。

Conclusion: CAB 揭示了现有模型在复杂项目环境中的局限性，强调了真实场景评估的重要性。

Abstract: Programming assistants powered by large language models have transformed
software development, yet most benchmarks focus narrowly on code generation
tasks. Recent efforts like InfiBench and StackEval attempt to address this gap
using Stack Overflow data but remain limited to single-turn interactions in
isolated contexts, require significant manual curation, and fail to represent
complete project environments. We introduce CodeAssistBench (CAB), the first
benchmark framework for evaluating multi-turn programming assistance in
realistic settings that address real-world questions about actual codebases.
Unlike existing programming Q&A benchmarks, CAB automatically generates
scalable datasets from question-related GitHub issues using configurable
parameters (e.g., repository creation date, star count, programming languages),
and includes automatic containerization of codebases for evaluation. It then
evaluates models through simulated users in these containerized environments
with full codebase access. Using this framework, we constructed a test set of
3,286 real-world programming questions across 231 repositories, spanning seven
programming languages and diverse problem domains. Our evaluation of leading
LLMs reveals a substantial capability gap: while models perform well on Stack
Overflow questions with success rates of 70-83%, they resolve only up to 16.49%
of CAB's recent issues. This discrepancy highlights the challenges of providing
assistance in complex, project-specific contexts versus answering standalone
questions.

</details>


### [8] [Toward Realistic Evaluations of Just-In-Time Vulnerability Prediction](https://arxiv.org/abs/2507.10729)
*Duong Nguyen,Thanh Le-Cong,Triet Huynh Minh Le,M. Ali Babar,Quyet-Thang Huynh*

Main category: cs.SE

TL;DR: 该研究评估了即时漏洞预测（JIT-VP）在真实场景下的有效性，发现其在现实数据集上性能显著下降，并提出现有数据不平衡处理技术效果有限。


<details>
  <summary>Details</summary>
Motivation: 当前JIT-VP评估依赖理想化数据集，缺乏对现实场景中漏洞相关和无关提交的考虑，研究旨在填补这一空白。

Method: 引入包含FFmpeg和Linux内核的百万级提交数据集，评估八种先进JIT-VP技术，并探索数据不平衡处理技术。

Result: 现实条件下JIT-VP性能大幅下降（如Linux的PR-AUC从0.805降至0.016），现有不平衡处理技术效果不佳。

Conclusion: 强调JIT-VP需基于真实场景评估，并需开发领域特定技术以解决数据不平衡问题。

Abstract: Modern software systems are increasingly complex, presenting significant
challenges in quality assurance. Just-in-time vulnerability prediction (JIT-VP)
is a proactive approach to identifying vulnerable commits and providing early
warnings about potential security risks. However, we observe that current
JIT-VP evaluations rely on an idealized setting, where the evaluation datasets
are artificially balanced, consisting exclusively of vulnerability-introducing
and vulnerability-fixing commits.
  To address this limitation, this study assesses the effectiveness of JIT-VP
techniques under a more realistic setting that includes both
vulnerability-related and vulnerability-neutral commits. To enable a reliable
evaluation, we introduce a large-scale public dataset comprising over one
million commits from FFmpeg and the Linux kernel. Our empirical analysis of
eight state-of-the-art JIT-VP techniques reveals a significant decline in
predictive performance when applied to real-world conditions; for example, the
average PR-AUC on Linux drops 98\% from 0.805 to 0.016. This discrepancy is
mainly attributed to the severe class imbalance in real-world datasets, where
vulnerability-introducing commits constitute only a small fraction of all
commits.
  To mitigate this issue, we explore the effectiveness of widely adopted
techniques for handling dataset imbalance, including customized loss functions,
oversampling, and undersampling. Surprisingly, our experimental results
indicate that these techniques are ineffective in addressing the imbalance
problem in JIT-VP. These findings underscore the importance of realistic
evaluations of JIT-VP and the need for domain-specific techniques to address
data imbalance in such scenarios.

</details>


### [9] [GenAI-Enabled Backlog Grooming in Agile Software Projects: An Empirical Study](https://arxiv.org/abs/2507.10753)
*Kasper Lien Oftebro,Anh Nguyen-Duc,Kai-Kristian Kemell*

Main category: cs.SE

TL;DR: 研究探讨了使用生成式AI助手自动管理敏捷项目中的待办事项清单，通过Jira插件实现高精度和高效的时间节省。


<details>
  <summary>Details</summary>
Motivation: 随着待办事项清单规模和复杂性的增加，冗余和模糊任务导致优先级和决策困难，需探索AI自动化解决方案。

Method: 通过设计科学周期开发Jira插件，利用向量数据库和GPT-4o模型检测重复任务并提出优化建议。

Result: AI辅助的待办事项管理实现了100%的精确度，并将完成时间减少了45%。

Conclusion: 该工具能有效优化待办事项管理流程并提升用户体验。

Abstract: Effective backlog management is critical for ensuring that development teams
remain aligned with evolving requirements and stakeholder expectations.
However, as product backlogs consistently grow in scale and complexity, they
tend to become cluttered with redundant, outdated, or poorly defined tasks,
complicating prioritization and decision making processes. This study
investigates whether a generative-AI (GenAI) assistant can automate backlog
grooming in Agile software projects without sacrificing accuracy or
transparency. Through Design Science cycles, we developed a Jira plug-in that
embeds backlog issues with the vector database, detects duplicates via cosine
similarity, and leverage the GPT-4o model to propose merges, deletions, or new
issues. We found that AI-assisted backlog grooming achieved 100 percent
precision while reducing the time-to-completion by 45 percent. The findings
demonstrated the tool's potential to streamline backlog refinement processes
while improving user experiences.

</details>


### [10] [Towards a Closer Collaboration Between Practice and Research in Agile Software Development Workshop: A Summary and Research Agenda](https://arxiv.org/abs/2507.10785)
*Michael Neumann,Eva-Maria Schön,Mali Senapathi,Maria Rauschenberger,Tiago Silva da Silva*

Main category: cs.SE

TL;DR: 本文总结了首次国际研讨会的研究成果，探讨了敏捷软件开发中研究与实际应用之间的差距及其解决策略。


<details>
  <summary>Details</summary>
Motivation: 敏捷软件开发虽广泛应用，但研究与实际实施之间存在显著差距，需促进两者的协作。

Method: 通过首次国际研讨会，收集参与者对差距主题、影响因素及解决策略的讨论。

Result: 识别了导致差距的主要因素和挑战，并提出了可能的解决策略。

Conclusion: 需进一步研究以解决敏捷软件开发中研究与实际应用之间的差距。

Abstract: Agile software development principles and values have been widely adopted
across various industries, influencing products and services globally. Despite
its increasing popularity, a significant gap remains between research and
practical implementation. This paper presents the findings of the first
international workshop designed to foster collaboration between research and
practice in agile software development. We discuss the main themes and factors
identified by the workshop participants that contribute to this gap, strategies
to bridge it, and the challenges that require further research attention.

</details>


### [11] [How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow](https://arxiv.org/abs/2507.10818)
*Jasmine Latendresse,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: LLMs倾向于推荐成熟、流行的第三方库，但存在可用性差距，如依赖解析问题和安装指导不足。


<details>
  <summary>Details</summary>
Motivation: 了解LLMs如何推荐库对代码功能、安全和维护至关重要。

Method: 通过从Stack Overflow获取的Python问题，对六种LLMs进行实证研究，分析其推荐的库类型和特性。

Result: LLMs主要推荐第三方库，但4.6%的库因导入名称与可安装包不匹配而无法自动解析，仅两种模型提供安装指导。

Conclusion: 研究为开发者和研究人员提供了改进LLM生成代码可靠性和可用性的机会。

Abstract: Software libraries are central to the functionality, security, and
maintainability of modern code. As developers increasingly turn to Large
Language Models (LLMs) to assist with programming tasks, understanding how
these models recommend libraries is essential. In this paper, we conduct an
empirical study of six state-of-the-art LLMs, both proprietary and open-source,
by prompting them to solve real-world Python problems sourced from Stack
Overflow. We analyze the types of libraries they import, the characteristics of
those libraries, and the extent to which the recommendations are usable out of
the box. Our results show that LLMs predominantly favour third-party libraries
over standard ones, and often recommend mature, popular, and permissively
licensed dependencies. However, we also identify gaps in usability: 4.6% of the
libraries could not be resolved automatically due to structural mismatches
between import names and installable packages, and only two models (out of six)
provided installation guidance. While the generated code is technically valid,
the lack of contextual support places the burden of manually resolving
dependencies on the user. Our findings offer actionable insights for both
developers and researchers, and highlight opportunities to improve the
reliability and usability of LLM-generated code in the context of software
dependencies.

</details>


### [12] [Past, Present and Future: Exploring Adaptive AI in Software Development Bots](https://arxiv.org/abs/2507.10822)
*Omar Elsisi,Glaucia Melo*

Main category: cs.SE

TL;DR: 本文探讨了自适应AI驱动的对话代理在软件开发中的作用，强调其动态、上下文感知的辅助能力，并分析了其优势、挑战及未来潜力。


<details>
  <summary>Details</summary>
Motivation: 研究自适应AI对话代理如何通过机器学习和自然语言处理提升开发效率，解决传统规则系统的局限性。

Method: 通过分析自适应AI代理（如GitHub Copilot和Microsoft Teams机器人）的演变，评估其在软件开发中的应用和集成挑战。

Result: 自适应AI代理能提供个性化、实时的开发支持，显著提升开发效率，但也面临数据隐私和伦理问题。

Conclusion: 自适应AI对话代理有望通过定制化支持和高效开发周期革新软件开发领域。

Abstract: Conversational agents, such as chatbots and virtual assistants, have become
essential in software development, boosting productivity, collaboration, and
automating various tasks. This paper examines the role of adaptive AI-powered
conversational agents in software development, highlighting their ability to
offer dynamic, context-aware assistance to developers. Unlike traditional
rule-based systems, adaptive AI agents use machine learning and natural
language processing to learn from interactions and improve over time, providing
more personalized and responsive help. We look at how these tools have evolved
from simple query-based systems to advanced AI-driven solutions like GitHub
Copilot and Microsoft Teams bots. We also explore the challenges of integrating
adaptive AI into software development processes. The study aims to assess the
benefits and limitations of these systems, address concerns like data privacy
and ethical issues, and offer insights into their future use in the field.
Ultimately, adaptive AI chatbots have great potential to revolutionize software
development by delivering real-time, customized support and enhancing the
efficiency of development cycles.

</details>


### [13] [Evaluating Generated Commit Messages with Large Language Models](https://arxiv.org/abs/2507.10906)
*Qunhong Zeng,Yuxia Zhang,Zexiong Ma,Bo Jiang,Ningyuan Sun,Klaas-Jan Stol,Xingyu Mou,Hui Liu*

Main category: cs.SE

TL;DR: 该研究探讨了利用大型语言模型（LLMs）作为自动评估提交消息质量的工具，发现其结合链式思维推理和少量示例后，评估能力接近人类水平，显著优于传统指标。


<details>
  <summary>Details</summary>
Motivation: 提交消息在软件开发中至关重要，但质量参差不齐，传统自动评估指标（如BLEU、ROUGE-L）存在局限性，依赖人工评估成本高。

Method: 通过系统实验，研究结合链式思维推理和少量示例的LLMs，评估其在提交消息质量评估中的表现。

Result: LLMs评估器在保持可接受的重现性、鲁棒性和公平性的同时，显著优于传统指标，接近人类水平。

Conclusion: LLMs为提交消息质量评估提供了可扩展的高质量替代方案，减少了人工评估的依赖。

Abstract: Commit messages are essential in software development as they serve to
document and explain code changes. Yet, their quality often falls short in
practice, with studies showing significant proportions of empty or inadequate
messages. While automated commit message generation has advanced significantly,
particularly with Large Language Models (LLMs), the evaluation of generated
messages remains challenging. Traditional reference-based automatic metrics
like BLEU, ROUGE-L, and METEOR have notable limitations in assessing commit
message quality, as they assume a one-to-one mapping between code changes and
commit messages, leading researchers to rely on resource-intensive human
evaluation. This study investigates the potential of LLMs as automated
evaluators for commit message quality. Through systematic experimentation with
various prompt strategies and state-of-the-art LLMs, we demonstrate that LLMs
combining Chain-of-Thought reasoning with few-shot demonstrations achieve near
human-level evaluation proficiency. Our LLM-based evaluator significantly
outperforms traditional metrics while maintaining acceptable reproducibility,
robustness, and fairness levels despite some inherent variability. This work
conducts a comprehensive preliminary study on using LLMs for commit message
evaluation, offering a scalable alternative to human assessment while
maintaining high-quality evaluation.

</details>


### [14] [SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks](https://arxiv.org/abs/2507.11059)
*Pavel Adamenko,Mikhail Ivanov,Aidar Valeev,Rodion Levichev,Pavel Zadorozhny,Ivan Lopatin,Dmitry Babayev,Alena Fenogenova,Valentin Malykh*

Main category: cs.SE

TL;DR: 论文介绍了SWE-MERA，一个动态更新的基准测试，旨在解决SWE-bench中的数据污染问题，并通过自动化收集GitHub问题和严格验证提升质量。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试（如SWE-bench）存在数据污染和测试不足的问题，限制了大型语言模型（LLMs）在软件工程中的评估效果。

Method: 通过自动化收集真实GitHub问题并实施严格质量验证，构建动态更新的SWE-MERA基准测试。

Result: 生成了约10,000个潜在任务（当前300个样本可用），并在Aider编码代理上验证了其区分能力。评估了12个最新LLM的性能。

Conclusion: SWE-MERA通过动态更新和严格验证，有效解决了数据污染问题，为LLM评估提供了更可靠的基准。

Abstract: The rapid advancement of Large Language Models (LLMs) in software engineering
has revealed critical limitations in existing benchmarks, particularly the
widely used SWE-bench dataset. Recent studies have uncovered severe data
contamination issues, e.g. SWE-bench reports 32.67% of successful patches
involve direct solution leakage and 31.08\% pass due to inadequate test cases.
We introduce SWE-MERA, a dynamic, continuously updated benchmark designed to
address these fundamental challenges through an automated collection of
real-world GitHub issues and rigorous quality validation. Our approach
implements a reliable pipeline that ensures quality while minimizing
contamination risks, resulting in approximately 10,000 potential tasks with 300
samples currently available. Evaluation using the Aider coding agent
demonstrates strong discriminative power in state-of-the-art models. We report
performance across a dozen recent LLMs evaluated on tasks collected between
September 2024 and June 2025.

</details>


### [15] [MT4DP: Data Poisoning Attack Detection for DL-based Code Search Models via Metamorphic Testing](https://arxiv.org/abs/2507.11092)
*Gong Chen,Wenjie Liu,Xiaoyuan Xie,Xunzhu Tang,Tegawendé F. Bissyandé,Songqiang Chen*

Main category: cs.SE

TL;DR: MT4DP是一种基于蜕变测试的数据投毒攻击检测框架，用于深度学习代码搜索模型，通过语义等效蜕变关系显著提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 数据投毒攻击对深度学习代码搜索模型构成严重安全威胁，现有检测方法效果不足。

Method: MT4DP利用高频词识别潜在投毒目标，生成语义等效查询并重新排序，通过计算排名差异检测攻击。

Result: 实验显示MT4DP在F1分数和精确率上分别比基线方法提升191%和265%。

Conclusion: MT4DP有效提升数据投毒攻击检测能力，推动相关安全研究。

Abstract: Recently, several studies have indicated that data poisoning attacks pose a
severe security threat to deep learning-based (DL-based) code search models.
Attackers inject carefully crafted malicious patterns into the training data,
misleading the code search model to learn these patterns during training.
During the usage of the poisoned code search model for inference, once the
malicious pattern is triggered, the model tends to rank the vulnerability code
higher. However, existing detection methods for data poisoning attacks on
DL-based code search models remain insufficiently effective. To address this
critical security issue, we propose MT4DP, a Data Poisoning Attack Detection
Framework for DL-based Code Search Models via Metamorphic Testing. MT4DP
introduces a novel Semantically Equivalent Metamorphic Relation (SE-MR)
designed to detect data poisoning attacks on DL-based code search models.
Specifically, MT4DP first identifies the high-frequency words from search
queries as potential poisoning targets and takes their corresponding queries as
the source queries. For each source query, MT4DP generates two semantically
equivalent follow-up queries and retrieves its source ranking list. Then, each
source ranking list is re-ranked based on the semantic similarities between its
code snippets and the follow-up queries. Finally, variances between the source
and re-ranked lists are calculated to reveal violations of the SE-MR and warn
the data poisoning attack. Experimental results demonstrate that MT4DP
significantly enhances the detection of data poisoning attacks on DL-based code
search models, outperforming the best baseline by 191% on average F1 score and
265% on average precision. Our work aims to promote further research into
effective techniques for mitigating data poisoning threats on DL-based code
search models.

</details>


### [16] [Automata Models for Effective Bug Description](https://arxiv.org/abs/2507.11146)
*Tom Yaacov,Gera Weiss,Gal Amram,Avi Hayoun*

Main category: cs.SE

TL;DR: 论文提出了一种基于自动机学习和测试技术的调试方法，通过提取关键失败模式生成简洁的bug描述。


<details>
  <summary>Details</summary>
Motivation: 调试复杂系统耗时且困难，需要更高效的bug描述方法。

Method: 引入失败解释（FE）、最终失败解释（EFE）和早期检测（ED）概念，提取关键测试模式。

Result: 在多种测试模式和实际基准中验证了方法的有效性。

Conclusion: 该方法能生成紧凑且信息丰富的bug描述，提升调试效率。

Abstract: Debugging complex systems is a crucial yet time-consuming task. This paper
presents the use of automata learning and testing techniques to obtain concise
and informative bug descriptions. We introduce the concepts of Failure
Explanations (FE), Eventual Failure Explanations (EFE), and Early Detection
(ED) to provide meaningful summaries of failing behavior patterns. By factoring
out irrelevant information and focusing on essential test patterns, our
approach aims to enhance bug detection and understanding. We evaluate our
methods using various test patterns and real-world benchmarks, demonstrating
their effectiveness in producing compact and informative bug descriptions.

</details>


### [17] [New Formulation of DNN Statistical Mutation Killing for Ensuring Monotonicity: A Technical Report](https://arxiv.org/abs/2507.11199)
*Jinhan Kim,Nargiz Humbatova,Gunel Jahangirova,Shin Yoo,Paolo Tonella*

Main category: cs.SE

TL;DR: 提出了一种基于Fisher精确检验的统计突变杀死准则，解决了DeepCrime中违反单调性的问题。


<details>
  <summary>Details</summary>
Motivation: DeepCrime的统计突变杀死准则存在违反单调性的问题，即扩大测试集可能导致已杀死的突变不再被分类为杀死。

Method: 采用Fisher精确检验重新定义统计突变杀死准则，保持统计严谨性的同时确保单调性。

Result: 新方法在保持统计严谨性的同时解决了单调性问题。

Conclusion: 提出的Fisher精确检验方法有效解决了DeepCrime的单调性问题，同时保持了统计严谨性。

Abstract: Mutation testing has emerged as a powerful technique for evaluating the
effectiveness of test suites for Deep Neural Networks. Among existing
approaches, the statistical mutant killing criterion of DeepCrime has leveraged
statistical testing to determine whether a mutant significantly differs from
the original model. However, it suffers from a critical limitation: it violates
the monotonicity property, meaning that expanding a test set may result in
previously killed mutants no longer being classified as killed. In this
technical report, we propose a new formulation of statistical mutant killing
based on Fisher exact test that preserves the statistical rigour of it while
ensuring monotonicity.

</details>


### [18] [An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling](https://arxiv.org/abs/2507.11272)
*Anh Nguyen-Duc,Chien Vu Manh,Bao Anh Tran,Viet Phuong Ngo,Luan Le Chi,Anh Quang Nguyen*

Main category: cs.SE

TL;DR: MARAUS是一个结合多智能体、检索增强和LLM的大学招生咨询系统，在越南实际部署中表现出色，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的招生咨询系统多为原型或合成基准，MARAUS旨在填补这一空白，为实际应用提供高效、低成本的解决方案。

Method: 结合混合检索、多智能体协同和LLM生成技术，与越南河内运输技术大学合作进行技术开发和实际评估。

Result: 处理6000多次真实用户交互，平均准确率92%，幻觉率从15%降至1.45%，响应时间低于4秒，成本仅11.58美元。

Conclusion: MARAUS为低资源教育环境中部署智能检索增强系统提供了可行方案。

Abstract: This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University
Admission System), a real-world deployment of a conversational AI platform for
higher education admissions counseling in Vietnam. While large language models
(LLMs) offer potential for automating advisory tasks, most existing solutions
remain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap
by combining hybrid retrieval, multi-agent orchestration, and LLM-based
generation into a system tailored for real-world university admissions. In
collaboration with the University of Transport Technology (UTT) in Hanoi, we
conducted a two-phase study involving technical development and real-world
evaluation. MARAUS processed over 6,000 actual user interactions, spanning six
categories of queries. Results show substantial improvements over LLM-only
baselines: on average 92 percent accuracy, hallucination rates reduced from 15
precent to 1.45 percent, and average response times below 4 seconds. The system
operated cost-effectively, with a two-week deployment cost of 11.58 USD using
GPT-4o mini. This work provides actionable insights for the deployment of
agentic RAG systems in low-resource educational settings.

</details>


### [19] [RefModel: Detecting Refactorings using Foundation Models](https://arxiv.org/abs/2507.11346)
*Pedro Simões,Rohit Gheyi,Rian Melo,Jonhnanthan Oliveira,Márcio Ribeiro,Wesley K. G. Assunção*

Main category: cs.SE

TL;DR: 研究探讨了使用基础模型（如Phi4-14B、Claude 3.5 Sonnet等）检测代码重构的可行性，工具RefModel在性能上与传统工具相当甚至更优。


<details>
  <summary>Details</summary>
Motivation: 现有工具依赖复杂规则和静态分析，难以扩展和泛化到其他编程语言，因此探索更灵活的基础模型方法。

Method: 评估多个基础模型在人工生成的Java程序数据集和真实开源项目中的重构检测性能，并与传统工具对比。

Result: Claude 3.5 Sonnet和Gemini 2.5 Pro在真实场景中联合识别了97%的重构，优于传统工具，并展示了在Python和Golang中的泛化能力。

Conclusion: 基础模型在重构检测中具有竞争力，提供自然语言解释且定义简单，为未来工具开发提供了新方向。

Abstract: Refactoring is a common software engineering practice that improves code
quality without altering program behavior. Although tools like ReExtractor+,
RefactoringMiner, and RefDiff have been developed to detect refactorings
automatically, they rely on complex rule definitions and static analysis,
making them difficult to extend and generalize to other programming languages.
In this paper, we investigate the viability of using foundation models for
refactoring detection, implemented in a tool named RefModel. We evaluate
Phi4-14B, and Claude 3.5 Sonnet on a dataset of 858 single-operation
transformations applied to artificially generated Java programs, covering
widely-used refactoring types. We also extend our evaluation by including
Gemini 2.5 Pro and o4-mini-high, assessing their performance on 44 real-world
refactorings extracted from four open-source projects. These models are
compared against RefactoringMiner, RefDiff, and ReExtractor+. RefModel is
competitive with, and in some cases outperform, traditional tools. In
real-world settings, Claude 3.5 Sonnet and Gemini 2.5 Pro jointly identified
97% of all refactorings, surpassing the best-performing static-analysis-based
tools. The models showed encouraging generalization to Python and Golang. They
provide natural language explanations and require only a single sentence to
define each refactoring type.

</details>


### [20] [Security Debt in Practice: Nuanced Insights from Practitioners](https://arxiv.org/abs/2507.11362)
*Chaima Boufaied,Taher Ghaleb,Zainab Masood*

Main category: cs.SE

TL;DR: 论文通过定性实证研究探讨了软件从业者对安全债务（SDs）的认知、管理和沟通方式，发现实践中存在对安全的不同优先级和处理策略，强调了在软件开发生命周期中更紧密集成安全实践的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着软件和自动化的普及，时间、资源限制及功能优先于安全的做法导致安全债务积累，但缺乏实证研究探讨从业者如何实际处理这一问题。

Method: 通过半结构化访谈22名来自不同角色、组织和国家的软件从业者，研究其对安全债务的认知、行为、工具使用及风险沟通方式。

Result: 研究发现从业者对安全债务的认知和管理存在差异，部分人优先考虑交付速度而非安全，强调了安全实践在SDLC中的整合需求。

Conclusion: 研究呼吁更一致的安全缓解策略、平衡资源与安全任务，并关注CIA三要素，以改善安全债务管理。

Abstract: With the increasing reliance on software and automation nowadays, tight
deadlines, limited resources, and prioritization of functionality over security
can lead to insecure coding practices. When not handled properly, these
constraints cause unaddressed security vulnerabilities to accumulate over time,
forming Security Debts (SDs). Despite their critical importance, there is
limited empirical evidence on how software practitioners perceive, manage, and
communicate SDs in real-world settings. In this paper, we present a qualitative
empirical study based on semi-structured interviews with 22 software
practitioners across various roles, organizations, and countries. We address
four research questions: i) we assess software practitioners' knowledge of SDs
and awareness of associated security risks, ii) we investigate their behavior
towards SDs, iii) we explore common tools and strategies used to mitigate SDs,
and iv) we analyze how security risks are communicated within teams and to
decision makers. We observe variations in how practitioners perceive and manage
SDs, with some prioritizing delivery speed over security, while others
consistently maintain security as a priority. Our findings emphasize the need
for stronger integration of security practices across the Software Development
Life Cycle (SDLC), more consistent use of mitigation strategies, better
balancing of deadlines, resources, and security-related tasks, with attention
to the Confidentiality, Integrity, and Availability (CIA) triad.

</details>
