<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 15]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: 本文是一篇关于大语言模型在IT运维人工智能(AIOps)领域应用的综合调研，通过分析183篇2020-2024年发表的论文，从故障数据源、任务演化、方法应用和评估方法四个维度全面探讨了LLM4AIOps的现状、潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型日益复杂和普及，其在AIOps各种任务中的应用引起了广泛关注，但对LLM在AIOps领域的影响、潜力和局限性缺乏全面理解，需要系统性调研来填补这一知识空白。

Method: 通过详细调研分析2020年1月至2024年12月期间发表的183篇研究论文，围绕四个关键研究问题进行系统分析：RQ1探讨多样化故障数据源的利用；RQ2分析AIOps任务的演化；RQ3研究基于LLM的方法；RQ4审查评估方法论。

Result: 识别了LLM在AIOps中的多种数据源处理技术，包括对传统数据的高级LLM处理和新数据源的整合；发现了新兴AIOps任务和发表趋势；总结了各种LLM方法在解决AIOps挑战中的应用；梳理了专门针对LLM集成AIOps方法的评估方法。

Conclusion: 基于调研发现，讨论了最新进展和趋势，识别了现有研究的不足，并提出了未来探索的有前景方向，为LLM4AIOps领域的进一步发展提供了指导。

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [2] [LLM-Powered Quantum Code Transpilation](https://arxiv.org/abs/2507.12480)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 利用大型语言模型（LLMs）作为量子软件开发工具包（QSDKs）间的自动转译器，解决跨平台开发的互操作性问题。


<details>
  <summary>Details</summary>
Motivation: 量子计算平台多样性导致QSDKs间互操作性差，传统基于规则的转译器设计维护成本高。

Method: 利用LLMs的预训练知识和上下文推理能力，实现编程语言无关的量子程序转译。

Result: 提出了一种无需手动定义转换规则的可扩展量子软件移植方案。

Conclusion: LLMs为量子计算生态中的智能通用转译提供了可行路径。

Abstract: There exist various Software Development Kits (SDKs) tailored to different
quantum computing platforms. These are known as Quantum SDKs (QSDKs). Examples
include but are not limited to Qiskit, Cirq, and PennyLane. However, this
diversity presents significant challenges for interoperability and
cross-platform development of hybrid quantum-classical software systems.
Traditional rule-based transpilers for translating code between QSDKs are
time-consuming to design and maintain, requiring deep expertise and rigid
mappings in the source and destination code. In this study, we explore the use
of Large Language Models (LLMs) as a flexible and automated solution.
Leveraging their pretrained knowledge and contextual reasoning capabilities, we
position LLMs as programming language-agnostic transpilers capable of
converting quantum programs from one QSDK to another while preserving
functional equivalence. Our approach eliminates the need for manually defined
transformation rules and offers a scalable solution to quantum software
portability. This work represents a step toward enabling intelligent,
general-purpose transpilation in the quantum computing ecosystem.

</details>


### [3] [Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding](https://arxiv.org/abs/2507.12482)
*Ishraq Khan,Assad Chowdary,Sharoz Haseeb,Urvish Patel*

Main category: cs.SE

TL;DR: Kodezi Chronos是一种新型架构，用于自主代码理解、调试和维护，支持超长上下文，显著提升代码可靠性和生产力。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在代码生成和软件自动化中因上下文限制和缺乏显式代码结构推理而受到的根本约束。

Method: 采用多级嵌入内存引擎，结合向量和图索引，实现高效准确的代码推理，支持仓库级理解和实时自修复。

Result: 在真实世界错误检测中表现优于现有模型，提升23%，调试周期减少40%。

Conclusion: Kodezi Chronos标志着向自持续、持续优化的软件生态系统的关键进展。

Abstract: Large Language Models (LLMs) have advanced code generation and software
automation, but are fundamentally constrained by limited inference-time context
and lack of explicit code structure reasoning. We introduce Kodezi Chronos, a
next-generation architecture for autonomous code understanding, debugging, and
maintenance, designed to operate across ultra-long contexts comprising entire
codebases, histories, and documentation, all without fixed window limits.
Kodezi Chronos leverages a multi-level embedding memory engine, combining
vector and graph-based indexing with continuous code-aware retrieval. This
enables efficient and accurate reasoning over millions of lines of code,
supporting repository-scale comprehension, multi-file refactoring, and
real-time self-healing actions. Our evaluation introduces a novel Multi Random
Retrieval benchmark, specifically tailored to the software engineering domain.
Unlike classical retrieval benchmarks, this method requires the model to
resolve arbitrarily distant and obfuscated associations across code artifacts,
simulating realistic tasks such as variable tracing, dependency migration, and
semantic bug localization. Chronos outperforms prior LLMs and code models,
demonstrating a 23% improvement in real-world bug detection and reducing
debugging cycles by up to 40% compared to traditional sequence-based
approaches. By natively interfacing with IDEs and CI/CD workflows, Chronos
enables seamless, autonomous software maintenance, elevating code reliability
and productivity while reducing manual effort. These results mark a critical
advance toward self-sustaining, continuously optimized software ecosystems.

</details>


### [4] [A Survey of Reinforcement Learning for Software Engineering](https://arxiv.org/abs/2507.12483)
*Dong Wang,Hanmo You,Lingwei Zhu,Kaiwei Lin,Zheng Chen,Chen Yang,Junji Yu,Zan Wang,Junjie Chen*

Main category: cs.SE

TL;DR: 该论文对强化学习（RL）在软件工程（SE）中的应用进行了首次系统性综述，分析了115篇研究，总结了趋势、算法分类及挑战。


<details>
  <summary>Details</summary>
Motivation: 随着RL和大型语言模型（LLM）的发展，SE领域的复杂性增加，需要自动化解决方案，但缺乏对RL-for-SE的全面调查。

Method: 综述了115篇同行评审研究，分析了发表趋势、SE主题分类、RL算法、数据集使用、模型设计和评估实践。

Result: 总结了RL在SE中的应用现状，识别了开放挑战，并提出了未来研究方向。

Conclusion: 该调查为研究者和从业者提供了RL-for-SE的系统性指南，并公开了相关资源。

Abstract: Reinforcement Learning (RL) has emerged as a powerful paradigm for sequential
decision-making and has attracted growing interest across various domains,
particularly following the advent of Deep Reinforcement Learning (DRL) in 2015.
Simultaneously, the rapid advancement of Large Language Models (LLMs) has
further fueled interest in integrating RL with LLMs to enable more adaptive and
intelligent systems. In the field of software engineering (SE), the increasing
complexity of systems and the rising demand for automation have motivated
researchers to apply RL to a broad range of tasks, from software design and
development to quality assurance and maintenance. Despite growing research in
RL-for-SE, there remains a lack of a comprehensive and systematic survey of
this evolving field. To address this gap, we reviewed 115 peer-reviewed studies
published across 22 premier SE venues since the introduction of DRL. We
conducted a comprehensive analysis of publication trends, categorized SE topics
and RL algorithms, and examined key factors such as dataset usage, model design
and optimization, and evaluation practices. Furthermore, we identified open
challenges and proposed future research directions to guide and inspire ongoing
work in this evolving area. To summarize, this survey offers the first
systematic mapping of RL applications in software engineering, aiming to
support both researchers and practitioners in navigating the current landscape
and advancing the field. Our artifacts are publicly available:
https://github.com/KaiWei-Lin-lanina/RL4SE.

</details>


### [5] [When Retriever Meets Generator: A Joint Model for Code Comment Generation](https://arxiv.org/abs/2507.12558)
*Tien P. T. Le,Anh M. T. Bui,Huy N. D. Pham,Alessio Bucaioni,Phuong T. Nguyen*

Main category: cs.SE

TL;DR: RAGSum是一种结合检索与生成的代码注释生成方法，通过CodeT5框架实现高效推荐，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有检索增强方法中检索与生成分离导致的噪声传播问题，提升代码注释生成的效率与质量。

Method: 基于CodeT5框架，结合对比预训练和端到端训练，使用复合损失函数优化检索与生成，并引入轻量级自优化循环。

Result: 在Java、Python、C三种语言的基准测试中，RAGSum在BLEU、METEOR和ROUTE-L指标上显著优于基线模型。

Conclusion: 紧密耦合检索与生成能提升注释自动化的上限，未来可进一步验证和开展开发者研究。

Abstract: Automatically generating concise, informative comments for source code can
lighten documentation effort and accelerate program comprehension.
Retrieval-augmented approaches first fetch code snippets with existing comments
and then synthesize a new comment, yet retrieval and generation are typically
optimized in isolation, allowing irrelevant neighbors topropagate noise
downstream. To tackle the issue, we propose a novel approach named RAGSum with
the aim of both effectiveness and efficiency in recommendations. RAGSum is
built on top offuse retrieval and generation using a single CodeT5 backbone. We
report preliminary results on a unified retrieval-generation framework built on
CodeT5. A contrastive pre-training phase shapes code embeddings for
nearest-neighbor search; these weights then seed end-to-end training with a
composite loss that (i) rewards accurate top-k retrieval; and (ii) minimizes
comment-generation error. More importantly, a lightweight self-refinement loop
is deployed to polish the final output. We evaluated theframework on three
cross-language benchmarks (Java, Python, C), and compared it with three
well-established baselines. The results show that our approach substantially
outperforms thebaselines with respect to BLEU, METEOR, and ROUTE-L. These
findings indicate that tightly coupling retrieval and generationcan raise the
ceiling for comment automation and motivateforthcoming replications and
qualitative developer studies.

</details>


### [6] [ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells](https://arxiv.org/abs/2507.12561)
*Samal Nursapa,Anastassiya Samuilova,Alessio Bucaioni. Phuong T. Nguyen*

Main category: cs.SE

TL;DR: 论文探讨了使用预训练Transformer模型（CodeBERT和CodeT5）为检测到的架构异味推荐重构方法，CodeT5表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有工具能检测架构异味但缺乏修复建议，需填补这一空白。

Method: 将任务定义为三分类问题，在11000多个开源Java项目的200多万个重构实例上微调模型。

Result: CodeT5达到96.9%准确率和95.2% F1分数，优于CodeBERT和传统基线。

Conclusion: Transformer模型能有效连接异味检测与修复，为未来重构推荐系统奠定基础。

Abstract: Architectural smells such as God Class, Cyclic Dependency, and Hub-like
Dependency degrade software quality and maintainability. Existing tools detect
such smells but rarely suggest how to fix them. This paper explores the use of
pre-trained transformer models--CodeBERT and CodeT5--for recommending suitable
refactorings based on detected smells. We frame the task as a three-class
classification problem and fine-tune both models on over 2 million refactoring
instances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9%
accuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our
results show that transformer-based models can effectively bridge the gap
between smell detection and actionable repair, laying the foundation for future
refactoring recommendation systems. We release all code, models, and data under
an open license to support reproducibility and further research.

</details>


### [7] [QSpark: Towards Reliable Qiskit Code Generation](https://arxiv.org/abs/2507.12642)
*Kiana Kheiri,Aamna Aamir,Andriy Miranskyy,Chen Ding*

Main category: cs.SE

TL;DR: 论文研究了如何通过强化学习方法（GRPO和ORPO）优化量子编程模型，在Qiskit HumanEval基准测试中表现优于通用基线模型，但在高级任务上仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 量子电路需要具备容错能力，但现有大语言模型（如Granite-20B-Code和StarCoder）生成的Qiskit代码存在缺陷，因此需要改进。

Method: 使用两种强化学习方法（GRPO和ORPO）对32B模型进行微调，并利用丰富的合成数据集进行训练。

Result: 在Qiskit HumanEval基准测试中，ORPO达到56.29% Pass@1，GRPO为49%，均优于通用基线；在原始HumanEval中分别为65.90%和63.00%。GRPO在基础任务中表现更好（42/54），ORPO在中等任务中更优（41/68），但均未能解决高级任务。

Conclusion: 研究表明强化学习方法在AI辅助量子编程中具有显著优势，但在高级任务上仍需进一步改进。

Abstract: Quantum circuits must be error-resilient, yet LLMs like Granite-20B-Code and
StarCoder often output flawed Qiskit code. We fine-tuned a 32 B model with two
RL methods, Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference
Optimization (ORPO), using a richly annotated synthetic dataset. On the Qiskit
HumanEval benchmark, ORPO reaches 56.29\% Pass@1 ($\approx+10$ pp over
Granite-8B-QK) and GRPO hits 49\%, both beating all general-purpose baselines;
on the original HumanEval they score 65.90\% and 63.00\%. GRPO excels on basic
tasks (42/54), ORPO on intermediate ones (41/68), and neither solves the five
advanced tasks, highlighting clear gains yet room for progress in AI-assisted
quantum programming.

</details>


### [8] [A Three-Phase Evaluation Approach for new Information and Data Models in the Smart Grid Domain](https://arxiv.org/abs/2507.12649)
*Christine van Stiphoudt,Sergio Potenciano Menci,Gilbert Fridgen*

Main category: cs.SE

TL;DR: 本文提出了一种结合显性和隐性评估方法的三阶段评估方法，用于智能电网中新设计的信息和数据模型的开发过程。


<details>
  <summary>Details</summary>
Motivation: 智能电网数字化导致信息交换增加，现有模型不足，需在实施前评估新模型以避免潜在问题。

Method: 采用设计科学研究方法，设计了一个结合显性和隐性评估的三阶段评估方法，并以工业灵活性描述的信息和数据模型为例进行验证。

Result: 提出了一种适用于新模型开发的评估方法，并通过实际案例验证了其有效性。

Conclusion: 该方法填补了智能电网领域新模型评估的空白，并提供了实用的经验教训。

Abstract: The ongoing digitalisation of the smart grid is resulting in an increase in
automated information exchanges across distributed energy systems. This process
has led to the development of new information and data models when the existing
ones fall short. To prevent potential disruptions caused by flaws in the newly
designed information and data models, it is essential to evaluate them during
the design process before they are implemented in operation.
  Currently, general explicit evaluation approaches outside the smart grid
domain stay at a high level without defining clear steps. Meanwhile, implicit
evaluation approaches in the smart grid domain focus on testing systems that
utilise information and data models already in use for functionality in terms
of conformance and interoperability. Notably, no combination of explicit and
implicit evaluation approaches for newly designed information and data models
offers a clearly defined set of steps during their design process in the smart
grid context.
  Consequently, we design a three-phase evaluation approach using design
science research to address this gap. Our evaluation approach combines explicit
and implicit evaluation methods and is applicable when developing new
information and data models. We use the development of an information model and
data model focused on industrial flexibility descriptions to refine our
evaluation approach. Additionally, we provide lessons learned from our
experience.

</details>


### [9] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: 提出了一种基于模糊逻辑的项目成功评估新方法，优于传统的Likert量表。


<details>
  <summary>Details</summary>
Motivation: 传统Likert量表忽视了项目成功的多维性和情境依赖性，需要更动态的评估方法。

Method: 采用分层Type-1 Mamdani模糊系统，优先考虑对终端用户的持续积极影响。

Result: 该方法可能更准确地衡量项目成功，并适用于复杂评估。

Conclusion: 未来研究将聚焦于模糊逻辑在社会科学中的实证测试和广泛应用。

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>


### [10] [Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development](https://arxiv.org/abs/2507.12665)
*Salvador D. Escobedo*

Main category: cs.SE

TL;DR: 提出了一种名为SCM的新方法，通过单一对话结构利用LLMs进行软件开发，强调结构化对话和开发者主导。


<details>
  <summary>Details</summary>
Motivation: 纠正当前对LLMs的被动依赖，强调开发者在AI工具中的主动角色。

Method: 基于认知清晰性、可追溯性、模块化和文档化的原则，定义SCM的阶段、最佳实践和哲学立场。

Result: SCM提供了一种结构化且持久的开发对话方式，覆盖项目全生命周期。

Conclusion: SCM是一种必要的改进，重新确立了开发者作为AI工具架构师和监督者的角色。

Abstract: We propose the Single Conversation Methodology (SCM), a novel and pragmatic
approach to software development using large language models (LLMs). In
contrast to ad hoc interactions with generative AI, SCM emphasizes a structured
and persistent development dialogue, where all stages of a project - from
requirements to architecture and implementation - unfold within a single,
long-context conversation. The methodology is grounded on principles of
cognitive clarity, traceability, modularity, and documentation. We define its
phases, best practices, and philosophical stance, while arguing that SCM offers
a necessary correction to the passive reliance on LLMs prevalent in current
practices. We aim to reassert the active role of the developer as architect and
supervisor of the intelligent tool.

</details>


### [11] [Investigating the Performance of Small Language Models in Detecting Test Smells in Manual Test Cases](https://arxiv.org/abs/2507.13035)
*Keila Lucas,Rohit Gheyi,Márcio Ribeiro,Fabio Palomba,Luana Martins,Elvys Soares*

Main category: cs.SE

TL;DR: 研究探讨了小型语言模型（SLMs）在自动检测测试异味中的潜力，Phi-4表现最佳，准确率达97%。


<details>
  <summary>Details</summary>
Motivation: 手动测试中的测试异味（如模糊性、冗余）降低了测试的可靠性和可维护性，现有工具缺乏扩展性。

Method: 评估了Gemma3、Llama3.2和Phi-4在143个Ubuntu测试案例中的表现，覆盖七种测试异味类型。

Result: Phi-4在检测测试异味句子中达到97%的准确率，Gemma3和Llama3.2约为91%。SLMs还能自主解释问题并提出改进建议。

Conclusion: SLMs是高效工具，可低成本识别测试异味，提升测试质量，同时保护数据隐私。

Abstract: Manual testing, in which testers follow natural language instructions to
validate system behavior, remains crucial for uncovering issues not easily
captured by automation. However, these test cases often suffer from test
smells, quality issues such as ambiguity, redundancy, or missing checks that
reduce test reliability and maintainability. While detection tools exist, they
typically require manual rule definition and lack scalability. This study
investigates the potential of Small Language Models (SLMs) for automatically
detecting test smells. We evaluate Gemma3, Llama3.2, and Phi-4 on 143
real-world Ubuntu test cases, covering seven types of test smells. Phi-4
achieved the best results, reaching a pass@2 of 97% in detecting sentences with
test smells, while Gemma3 and Llama3.2 reached approximately 91%. Beyond
detection, SLMs autonomously explained issues and suggested improvements, even
without explicit prompt instructions. They enabled low-cost, concept-driven
identification of diverse test smells without relying on extensive rule
definitions or syntactic analysis. These findings highlight the potential of
SLMs as efficient tools that preserve data privacy and can improve test quality
in real-world scenarios.

</details>


### [12] [iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development](https://arxiv.org/abs/2507.13081)
*Dongming Jin,Weisong Sun,Jiangping Huang,Peng Liang,Jifeng Xuan,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: 提出了一种名为iReDev的知识驱动多智能体框架，用于智能需求开发，通过集成人类知识和事件驱动机制提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究对需求开发支持有限，且忽视了人类知识与智能体的结合及人机协作。

Method: iReDev包含六个知识驱动智能体，采用事件驱动通信机制和人工介入机制，支持全流程需求开发。

Result: iReDev在生成的需求规范上优于现有基线方法。

Conclusion: iReDev为智能需求开发提供了新方向，未来可进一步探索其潜力。

Abstract: Requirements development is a critical phase as it is responsible for
providing a clear understanding of what stakeholders need. It involves
collaboration among stakeholders to extract explicit requirements and address
potential conflicts, which is time-consuming and labor-intensive. Recently,
multi-agent systems for software development have attracted much attention.
However, existing research provides limited support for requirements
development and overlooks the injection of human knowledge into agents and the
human-agent collaboration. % To address these issues, this paper proposes a
knowledge-driven multi-agent framework for intelligent requirement development,
named iReDev. iReDev features: iReDev consists of six knowledge-driven agents
to support the entire requirements development. They collaboratively perform
various tasks to produce a software requirements specification. iReDev focuses
on integrating human knowledge for agents, enabling them to simulate real-world
stakeholders. iReDev uses an event-driven communication mechanism based on an
artifact pool. Agents continuously monitor the pool and autonomously trigger
the next action based on its changes, enabling iReDev to handle new
requirements quickly. iReDev introduces a human-in-the-loop mechanism to
support human-agent collaboration, ensuring that the generated artifacts align
with the expectations of stakeholders. We evaluated the generated artifacts and
results show that iReDev outperforms existing baselines in multiple aspects. We
further envision three key directions and hope this work can facilitate the
development of intelligent requirements development.

</details>


### [13] [A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems](https://arxiv.org/abs/2507.13095)
*Dongming Jin,Zhi Jin,Linyu Li,Xiaohong Chen*

Main category: cs.SE

TL;DR: 论文探讨了预训练模型在现代软件系统中的广泛应用及其对需求工程的挑战，提出了一个针对预训练模型软件系统的需求工程框架。


<details>
  <summary>Details</summary>
Motivation: 预训练模型的独特特性（如模糊能力边界、上下文依赖行为和持续演化）挑战了传统需求工程的假设，需要重新思考现有方法。

Method: 提出了一个针对预训练模型软件系统的需求工程概念框架，并概述了相关研究方向。

Result: 框架为研究人员和实践者提供了应对预训练模型软件系统需求工程挑战的指导。

Conclusion: 论文呼吁重新思考需求工程方法，以适应预训练模型软件系统的特性，并提出了未来研究方向。

Abstract: Recent advances in large pretrained models have led to their widespread
integration as core components in modern software systems. The trend is
expected to continue in the foreseeable future. Unlike traditional software
systems governed by deterministic logic, systems powered by pretrained models
exhibit distinctive and emergent characteristics, such as ambiguous capability
boundaries, context-dependent behavior, and continuous evolution. These
properties fundamentally challenge long-standing assumptions in requirements
engineering, including functional decomposability and behavioral
predictability. This paper investigates this problem and advocates for a
rethinking of existing requirements engineering methodologies. We propose a
conceptual framework tailored to requirements engineering of
pretrained-model-enabled software systems and outline several promising
research directions within this framework. This vision helps provide a guide
for researchers and practitioners to tackle the emerging challenges in
requirements engineering of pretrained-model-enabled systems.

</details>


### [14] [Inferring Attributed Grammars from Parser Implementations](https://arxiv.org/abs/2507.13117)
*Andreas Pointner,Josef Pichler,Herbert Prähofer*

Main category: cs.SE

TL;DR: 提出了一种从递归下降解析器实现中推断属性文法的新方法，以恢复输入处理的语义规范。


<details>
  <summary>Details</summary>
Motivation: 现有语法挖掘技术主要关注语法结构恢复，而输入处理的语义规范仍未被充分探索。

Method: 动态分析递归下降解析器的实现，通过观察程序执行将运行时行为映射到文法，并嵌入语义动作到文法规则中。

Result: 实验表明，该方法能准确通过生成的属性文法重现程序行为。

Conclusion: 该方法为恢复输入处理的语义规范提供了可行途径。

Abstract: Software systems that process structured inputs often lack complete and
up-to-date specifications, which specify the input syntax and the semantics of
input processing. While grammar mining techniques have focused on recovering
syntactic structures, the semantics of input processing remains largely
unexplored. In this work, we introduce a novel approach for inferring
attributed grammars from parser implementations. Given an input grammar, our
technique dynamically analyzes the implementation of recursive descent parsers
to reconstruct the semantic aspects of input handling, resulting in
specifications in the form of attributed grammars. By observing program
executions and mapping the program's runtime behavior to the grammar, we
systematically extract and embed semantic actions into the grammar rules. This
enables comprehensive specification recovery. We demonstrate the feasibility of
our approach using an initial set of programs, showing that it can accurately
reproduce program behavior through the generated attributed grammars.

</details>


### [15] [Detecting LLM-generated Code with Subtle Modification by Adversarial Training](https://arxiv.org/abs/2507.13123)
*Xin Yin,Xinrui Li,Chao Ni,Xiaodan Xu,Xiaohu Yang*

Main category: cs.SE

TL;DR: 论文提出CodeGPTSensor+，通过对抗训练提升对修改后LLM生成代码的检测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM生成代码的广泛应用，其检测面临代码修改带来的挑战，现有方法鲁棒性不足。

Method: 采用对抗训练，集成MIST模块生成高质量对抗样本。

Result: 在HMCorp数据集上，CodeGPTSensor+显著提升对抗测试集的检测准确率。

Conclusion: CodeGPTSensor+在保持高准确率的同时，展现出更强的鲁棒性。

Abstract: With the rapid development of Large Language Models (LLMs), their powerful
code-generation capabilities have been widely applied in tasks like code
completion and automated development, demonstrating the value of improving
coding efficiency. However, the extensive use of LLM-generated code also raises
several new challenges. On the one hand, issues such as the regulation of code
provenance, copyright disputes, and code quality have become increasingly
concerning. How to effectively detect LLM-generated code and ensure its
compliant and responsible use has become a critical and urgent issue. On the
other hand, in practical applications, LLM-generated code is often subject to
manual modifications, such as variable renaming or structural adjustments.
Although some recent studies have proposed training-based and zero-shot methods
for detecting LLM-generated code, these approaches show insufficient robustness
when facing modified LLM-generated code, and there is a lack of an effective
solution. To address the real-world scenario where LLM-generated code may
undergo minor modifications, we propose CodeGPTSensor+, an enhanced version of
CodeGPTSensor, which employs adversarial training to improve robustness against
input perturbations. CodeGPTSensor+ integrates an adversarial sample generation
module, Multi-objective Identifier and Structure Transformation (MIST), which
systematically generates both high-quality and representative adversarial
samples. This module effectively enhances the model's resistance against
diverse adversarial attacks. Experimental results on the HMCorp dataset
demonstrate that CodeGPTSensor+ significantly improves detection accuracy on
the adversarial test set while maintaining high accuracy on the original test
set, showcasing superior robustness compared to CodeGPTSensor.

</details>
