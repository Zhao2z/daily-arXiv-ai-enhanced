<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 41]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Choosing the Right Git Workflow: A Comparative Analysis of Trunk-based vs. Branch-based Approaches](https://arxiv.org/abs/2507.08943)
*Pedro Lopes,Paola Accioly,Paulo Borba,Vitor Menezes*

Main category: cs.SE

TL;DR: 论文探讨了Git工作流的两种主要类型（分支工作流和主干工作流），并通过调查和访谈分析了巴西开发者的使用情况及其影响因素。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于Git工作流的选择对团队生产力和软件质量的影响，但缺乏科学文献支持。

Method: 采用半结构化访谈和问卷调查的方法，收集巴西开发者的实际使用数据。

Result: 结果显示，主干工作流适合经验丰富的小团队和快节奏项目，而分支工作流更适合经验不足的大团队，尽管管理难度较大。

Conclusion: 结论指出，选择工作流应根据团队特点和项目需求，以优化生产力和质量。

Abstract: Git has become one of the most widely used version control systems today.
Among its distinguishing features, its ability to easily and quickly create
branches stands out, allowing teams to customize their workflows. In this
context, various formats of collaborative development workflows using Git have
emerged and gained popularity among software engineers. We can categorize such
workflows into two main types: branch-based workflows and trunk-based
workflows. Branch-based workflows typically define a set of remote branches
with well-defined objectives, such as feature branches, a branch for feature
integration, and a main branch. The goal is to migrate changes from the most
isolated branch to the main one shared by all as the code matures. In this
category, GitFlow stands out as the most popular example. In contrast,
trunk-based workflows have a single remote branch where developers integrate
their changes directly. In this range of options, choosing a workflow that
maximizes team productivity while promoting software quality becomes a
non-trivial task. Despite discussions on forums, social networks, and blogs,
few scientific articles have explored this topic. In this work, we provide
evidence on how Brazilian developers work with Git workflows and what factors
favor or hinder the use of each model. To this end, we conducted
semi-structured interviews and a survey with software developers. Our results
indicate that trunk-based development favors fast-paced projects with
experienced and smaller teams, while branch-based development suits less
experienced and larger teams better, despite posing management challenges.

</details>


### [2] [Semantic Source Code Segmentation using Small and Large Language Models](https://arxiv.org/abs/2507.08992)
*Abdelhalim Dahou,Ansgar Scherp,Sebastian Kurten,Brigitte Mathiak,Madhu Chauhan*

Main category: cs.SE

TL;DR: 论文提出了一种自动化、领域特定的R代码分割方法，使用大语言模型（LLMs）和小语言模型（SLMs），并比较了两种方法的效果。


<details>
  <summary>Details</summary>
Motivation: 随着代码库的增长，手动和基于语法分析的代码分割方法变得不切实际，尤其是对于R等低资源语言及其研究领域。

Method: 提出了两种新颖的方法：基于上下文的行分析和基于范围的段确定，并实验了LLMs和微调的SLMs。

Result: 基于上下文的行分析优于基于范围的分割，且CodeBERT和CodeT5+等小模型表现优于LLMs。

Conclusion: 小模型在未预训练R代码的情况下，仅通过微调少量标注数据即可取得优异表现。

Abstract: Source code segmentation, dividing code into functionally coherent segments,
is crucial for knowledge retrieval and maintenance in software development.
While enabling efficient navigation and comprehension of large codebases,
manual and syntactic analysis approaches have become impractical as
repositories grow, especially for low-resource languages like R and their
research domains (e.g., social sciences, psychology).This paper introduces an
automated, domain-specific approach for research R code segmentation using
Large and Small Language Models (LLMs/SLMs). It presents two novel approaches
and a human-annotated dataset, StatCodeSeg. We explore two distinct approaches:
line-by-line analysis with context and range-based segment determination. We
experiment with LLMs and fine-tuned SLMs. To support the generalizability of
our approaches, we also include experiments on Python code from the computer
science domain.Our results show that context-based line-by-line analysis is
superior over range-based segmentation.Using smaller language models like
CodeBERT and an encoder-only version of CodeT5+ are better than their LLM
counterparts. Most notably, these two best-performing models did not see R code
during pre-training versus the LLMs but were only fine-tuned on 4,130 lines of
manually annotated code.

</details>


### [3] [Accelerating Drug Discovery Through Agentic AI: A Multi-Agent Approach to Laboratory Automation in the DMTA Cycle](https://arxiv.org/abs/2507.09023)
*Yao Fehlis,Charles Crain,Aidan Jensen,Michael Watson,James Juhasz,Paul Mandel,Betty Liu,Shawn Mahon,Daren Wilson,Nick Lynch-Jonely,Ben Leedom,David Fuller*

Main category: cs.SE

TL;DR: 本文介绍了一种名为Tippy的新型AI框架，通过专门设计的AI代理自动化药物发现中的DMTA循环，显著提升了效率和决策速度。


<details>
  <summary>Details</summary>
Motivation: 传统药物发现方法难以满足现代治疗开发需求，需要更高效的自动化解决方案。

Method: Tippy采用多代理系统，包括五个专门代理（Supervisor、Molecule、Lab、Analysis、Report）和Safety Guardrail监督，覆盖DMTA循环的各个阶段。

Result: Tippy显著提升了工作流效率、决策速度和跨学科协作，为AI辅助药物发现提供了新范式。

Conclusion: Tippy是首个生产就绪的AI代理系统，展示了AI如何通过自主代理改变实验室工作流程。

Abstract: The pharmaceutical industry faces unprecedented challenges in drug discovery,
with traditional approaches struggling to meet modern therapeutic development
demands. This paper introduces a novel AI framework, Tippy, that transforms
laboratory automation through specialized AI agents operating within the
Design-Make-Test-Analyze (DMTA) cycle. Our multi-agent system employs five
specialized agents - Supervisor, Molecule, Lab, Analysis, and Report, with
Safety Guardrail oversight - each designed to excel in specific phases of the
drug discovery pipeline. Tippy represents the first production-ready
implementation of specialized AI agents for automating the DMTA cycle,
providing a concrete example of how AI can transform laboratory workflows. By
leveraging autonomous AI agents that reason, plan, and collaborate, we
demonstrate how Tippy accelerates DMTA cycles while maintaining scientific
rigor essential for pharmaceutical research. The system shows significant
improvements in workflow efficiency, decision-making speed, and
cross-disciplinary coordination, offering a new paradigm for AI-assisted drug
discovery.

</details>


### [4] [Towards Extracting Software Requirements from App Reviews using Seq2seq Framework](https://arxiv.org/abs/2507.09039)
*Aakash Sorathiya,Gouri Ginde*

Main category: cs.SE

TL;DR: 论文提出了一种基于序列到序列（Seq2seq）生成方法的命名实体识别（NER）任务，用于从移动应用评论中提取需求，解决了现有方法因评论语言不规范、信息无关等问题。


<details>
  <summary>Details</summary>
Motivation: 移动应用评论是软件改进的重要数据源，但现有方法因评论的语法错误、拼写错误和无关信息而效果不佳。

Method: 提出了一种结合BiLSTM编码器、LSTM解码器、自注意力机制、GloVe嵌入和CRF模型的Seq2seq框架。

Result: 在两个数据集上评估，F1分数分别为0.96（数据集2）和0.47（数据集1），优于现有方法。

Conclusion: 该方法能有效从非正式评论中提取需求，支持软件演化。

Abstract: Mobile app reviews are a large-scale data source for software improvements. A
key task in this context is effectively extracting requirements from app
reviews to analyze the users' needs and support the software's evolution.
Recent studies show that existing methods fail at this task since app reviews
usually contain informal language, grammatical and spelling errors, and a large
amount of irrelevant information that might not have direct practical value for
developers. To address this, we propose a novel reformulation of requirements
extraction as a Named Entity Recognition (NER) task based on the
sequence-to-sequence (Seq2seq) generation approach. With this aim, we propose a
Seq2seq framework, incorporating a BiLSTM encoder and an LSTM decoder, enhanced
with a self-attention mechanism, GloVe embeddings, and a CRF model. We
evaluated our framework on two datasets: a manually annotated set of 1,000
reviews (Dataset 1) and a crowdsourced set of 23,816 reviews (Dataset 2). The
quantitative evaluation of our framework showed that it outperformed existing
state-of-the-art methods with an F1 score of 0.96 on Dataset 2, and achieved
comparable performance on Dataset 1 with an F1 score of 0.47.

</details>


### [5] [CMER: A Context-Aware Approach for Mining Ethical Concern-related App Reviews](https://arxiv.org/abs/2507.09049)
*Aakash Sorathiya,Gouri Ginde*

Main category: cs.SE

TL;DR: CMER是一种结合自然语言推理（NLI）和大型语言模型（LLM）的新方法，用于从应用评论中提取伦理关注内容，如隐私和安全问题。


<details>
  <summary>Details</summary>
Motivation: 移动应用中伦理问题日益突出，但相关评论因领域特定语言和通用反馈的掩盖而难以自动化提取。

Method: CMER结合NLI（提供领域特定上下文）和LLM（无需标注数据），从382K条投资应用评论中提取隐私和安全相关评论。

Result: CMER提取了2178条之前基于关键词方法遗漏的隐私和安全相关评论，验证了其有效性。

Conclusion: CMER能有效提取伦理关注相关评论，为需求工程提供可操作的参考。

Abstract: With the increasing proliferation of mobile applications in our daily lives,
the concerns surrounding ethics have surged significantly. Users communicate
their feedback in app reviews, frequently emphasizing ethical concerns, such as
privacy and security. Incorporating these reviews has proved to be useful for
many areas of software engineering (e.g., requirement engineering, testing,
etc.). However, app reviews related to ethical concerns generally use
domain-specific language and are typically overshadowed by more generic
categories of user feedback, such as app reliability and usability. Thus,
making automated extraction a challenging and time-consuming effort.
  This study proposes CMER (A \underline{C}ontext-Aware Approach for
\underline{M}ining \underline{E}thical Concern-related App
\underline{R}eviews), a novel approach that combines Natural Language Inference
(NLI) and a decoder-only (LLaMA-like) Large Language Model (LLM) to extract
ethical concern-related app reviews at scale. In CMER, NLI provides
domain-specific context awareness by using domain-specific hypotheses, and the
Llama-like LLM eliminates the need for labeled data in the classification task.
We evaluated the validity of CMER by mining privacy and security-related
reviews (PSRs) from the dataset of more than 382K app reviews of mobile
investment apps. First, we evaluated four NLI models and compared the results
of domain-specific hypotheses with generic hypotheses. Next, we evaluated three
LLMs for the classification task. Finally, we combined the best NLI and LLM
models (CMER) and extracted 2,178 additional PSRs overlooked by the previous
study using a keyword-based approach, thus demonstrating the effectiveness of
CMER. These reviews can be further refined into actionable requirement
artifacts.

</details>


### [6] [SAGE: A Context-Aware Approach for Mining Privacy Requirements Relevant Reviews from Mental Health Apps](https://arxiv.org/abs/2507.09051)
*Aakash Sorathiya,Gouri Ginde*

Main category: cs.SE

TL;DR: SAGE是一种基于自然语言推理（NLI）和GPT模型的上下文感知方法，用于自动挖掘心理健康应用中的隐私相关评论，无需微调即可达到高准确率。


<details>
  <summary>Details</summary>
Motivation: 心理健康应用的数据收集引发隐私担忧，但隐私评论常被其他反馈类别掩盖，难以自动识别。

Method: 结合NLI和GPT模型，利用领域特定的隐私假设，自动挖掘隐私评论。

Result: SAGE在204K条评论中F1得分为0.85，优于微调的BERT和T5模型，并发现748条被忽略的隐私评论。

Conclusion: SAGE能有效识别隐私评论，为隐私需求提取提供支持。

Abstract: Mental health (MH) apps often require sensitive user data to customize
services for mental wellness needs. However, such data collection practices in
some MH apps raise significant privacy concerns for users. These concerns are
often mentioned in app reviews, but other feedback categories, such as
reliability and usability, tend to take precedence. This poses a significant
challenge in automatically identifying privacy requirements-relevant reviews
(privacy reviews) that can be utilized to extract privacy requirements and
address users' privacy concerns. Thus, this study introduces SAGE, a
context-aware approach to automatically mining privacy reviews from MH apps
using Natural Language Inference (NLI) with MH domain-specific privacy
hypotheses (provides domain-specific context awareness) and a GPT model
(eliminates the need for fine-tuning). The quantitative evaluation of SAGE on a
dataset of 204K app reviews achieved an F1 score of 0.85 without any
fine-tuning, outperforming the fine-tuned baseline classifiers BERT and T5.
Furthermore, SAGE extracted 748 privacy reviews previously overlooked by
keyword-based methods, demonstrating its effectiveness through qualitative
evaluation. These reviews can later be refined into actionable privacy
requirement artifacts.

</details>


### [7] [SetupBench: Assessing Software Engineering Agents' Ability to Bootstrap Development Environments](https://arxiv.org/abs/2507.09063)
*Avi Arora,Jinu Jang,Roshanak Zilouchian Moghaddam*

Main category: cs.SE

TL;DR: SetupBench是一个新的基准测试，用于评估LLM代理在裸Linux环境中完成软件任务的能力，发现现有代理在环境引导方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要在预配置环境中评估LLM代理，无法反映真实世界任务的复杂性，因此需要一种新的测试方法。

Method: 引入SetupBench，包含93个任务，涵盖多种语言生态系统、数据库引擎和多服务编排场景，通过自然语言问题描述和确定性成功命令进行评估。

Result: 评估显示，现有代理在环境引导任务中成功率低，特别是在仓库设置和本地数据库配置方面，且存在系统性失败模式和低效行为。

Conclusion: SetupBench填补了现有评估空白，为下一代软件开发者代理提供了严格的测试标准。

Abstract: Modern Large Language Model (LLM) agents promise end to end assistance with
real-world software tasks, yet existing benchmarks evaluate LLM agents almost
exclusively in pre-baked environments where every dependency is pre-installed.
To fill this gap, we introduce SetupBench, a 93 instance benchmark that
isolates the environment-bootstrap skill: starting from a bare Linux sandbox,
an agent must install packages, resolve dependency conflicts, initialize
databases, and configure background services. Our tasks span seven language
ecosystems, five database engines, and multi-service orchestration scenarios,
each accompanies by a natural language problem statement and a deterministic
success command. Through evaluation of OpenHands, a state-of-the-art coding
agent, we find low success rates across task categories, with particular
challenges in repository setup (38.9-57.4%) and local database configuration
(20.0-53.3%). Our analysis reveals systematic failure modes including
incomplete development tooling installation, hallucinated task constraints, and
non-persistent environment modifications that break agent-human collaboration
workflows. We identify substantial inefficiencies in agent exploration
strategies, with 38-89% of actions being unnecessary compared to optimal human
behavior. These findings highlight gaps in current agents' practical
environment-bootstrap capabilities. By targeting this critical yet
under-evaluated capability, SetupBench provides a rigorous yard-stick for the
next generation of software developer agents aiming to solve end to end
real-wold tasks.

</details>


### [8] [SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation](https://arxiv.org/abs/2507.09108)
*Aaditya Bhatia,Gustavo A. Oliva,Gopi Krishnan Rajbahadur,Haoxiang Zhang,Yihao Chen,Zhilong Chen,Arthur Leung,Dayi Lin,Boyuan Chen,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: SPICE是一个自动化标注工具，用于生成高质量的软件工程数据集，显著降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 高质量标注数据集对训练和评估基础模型至关重要，但手动标注成本高昂且耗时。

Method: SPICE结合上下文感知代码导航、基于理由的提示和多轮共识，生成接近专家标注的标签。

Result: SPICE在1000个实例上的标注成本从10万美元降至5.10美元，并与人工标注数据高度一致。

Conclusion: SPICE能够低成本、大规模地创建软件工程数据集，并发布了工具和新数据集SPICE Bench。

Abstract: High-quality labeled datasets are crucial for training and evaluating
foundation models in software engineering, but creating them is often
prohibitively expensive and labor-intensive. We introduce SPICE, a scalable,
automated pipeline for labeling SWE-bench-style datasets with annotations for
issue clarity, test coverage, and effort estimation. SPICE combines
context-aware code navigation, rationale-driven prompting, and multi-pass
consensus to produce labels that closely approximate expert annotations.
SPICE's design was informed by our own experience and frustration in labeling
more than 800 instances from SWE-Gym. SPICE achieves strong agreement with
human-labeled SWE-bench Verified data while reducing the cost of labeling 1,000
instances from around $100,000 (manual annotation) to just $5.10. These results
demonstrate SPICE's potential to enable cost-effective, large-scale dataset
creation for SE-focused FMs. To support the community, we release both SPICE
tool and SPICE Bench, a new dataset of 6,802 SPICE-labeled instances curated
from 291 open-source projects in SWE-Gym (over 13x larger than SWE-bench
Verified).

</details>


### [9] [Position Paper: Programming Language Techniques for Bridging LLM Code Generation Semantic Gaps](https://arxiv.org/abs/2507.09135)
*Yalong Du,Chaozheng Wang,Huaijin Wang*

Main category: cs.SE

TL;DR: 论文主张通过编程语言（PL）技术弥补大型语言模型（LLM）在代码生成中的语义缺陷，提升代码的可靠性和可信任性。


<details>
  <summary>Details</summary>
Motivation: LLM在代码生成中存在语法错误、语义幻觉和可靠性问题，需要PL技术弥补这些缺陷。

Method: 提出通过结构化程序表示、形式化正确性保证和鲁棒验证机制，将PL技术与LLM结合。

Result: PL技术可将LLM生成的代码从统计模式匹配提升到可靠、可信任的水平。

Conclusion: PL与LLM的整合对生成功能正确、可解释、可验证且可信的代码至关重要。

Abstract: Large Language Models have demonstrated remarkable capabilities in automated
code generation, yet their statistical nature and black-box characteristics
create significant semantic gaps manifested through syntax errors, semantic
hallucinations, and reliability concerns. This position paper argues that
principled integration of Programming Language (PL) techniques is essential for
bridging these gaps. Through structured program representations, formal
correctness guarantees, and robust verification mechanisms, PL techniques can
elevate LLM-generated code from statistical pattern matching to truly reliable
and trustworthy levels. This integration is crucial for developing systems that
generate code that is not only functionally correct but also interpretable,
verifiable, and ultimately trustworthy.

</details>


### [10] [OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advanced Transportation Research](https://arxiv.org/abs/2507.09186)
*Minhaj Uddin Ahmad,Akid Abrar,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.SE

TL;DR: OpenCAMS是一个开源、同步且可扩展的协同仿真平台，整合了SUMO、CARLA和OMNeT++三大仿真工具，用于交通、感知和通信领域的研究。


<details>
  <summary>Details</summary>
Motivation: 支持交通安全性、移动性和网络安全的高级研究，通过结合不同仿真工具的优势，提供更全面的解决方案。

Method: 采用时间同步的双向耦合架构，确保交通、感知和通信领域的仿真一致性，同时保持模块化和可扩展性。

Result: OpenCAMS平台开源可用，为研究社区提供了灵活、协作的环境，支持下一代智能交通系统的发展。

Conclusion: OpenCAMS通过整合三大仿真工具，提供了一个强大且可扩展的研究平台，推动了智能交通系统的创新。

Abstract: We introduce OpenCAMS (Open-Source Connected and Automated Mobility
Co-Simulation Platform), an open-source, synchronized, and extensible
co-simulation framework that tightly couples three best-in-class simulation
tools: (i) SUMO, (ii) CARLA, and (iii) OMNeT++. OpenCAMS is designed to support
advanced research in transportation safety, mobility, and cybersecurity by
combining the strengths of each simulation domain. Specifically, SUMO provides
large-scale, microscopic traffic modeling; CARLA offers high-fidelity 3D
perception, vehicle dynamics, and control simulation; and OMNeT++ enables
modular, event-driven network communication, such as cellular
vehicle-to-everything (C-V2X). OpenCAMS employs a time-synchronized,
bidirectional coupling architecture that ensures coherent simulation
progression across traffic, perception, and communication domains while
preserving modularity and reproducibility. For example, CARLA can simulate and
render a subset of vehicles that require detailed sensor emulation and control
logic; SUMO orchestrates network-wide traffic flow, vehicle routing, and
traffic signal management; and OMNeT++ dynamically maps communication nodes to
both mobile entities (e.g., vehicles) and static entities (e.g., roadside
units) to enable C-V2X communication. While these three simulators form the
foundational core of OpenCAMS, the platform is designed to be expandable and
future-proof, allowing additional simulators to be integrated on top of this
core without requiring fundamental changes to the system architecture. The
OpenCAMS platform is fully open-source and publicly available through its
GitHub repository https://github.com/minhaj6/carla-sumo-omnetpp-cosim,
providing the research community with an accessible, flexible, and
collaborative environment for advancing next-generation intelligent
transportation systems.

</details>


### [11] [Back to the Basics: Rethinking Issue-Commit Linking with LLM-Assisted Retrieval](https://arxiv.org/abs/2507.09199)
*Huihui Huang,Ratnadira Widyasari,Ting Zhang,Ivana Clairine Irsan,Jieke Shi,Han Wei Ang,Frank Liauw,Eng Lieh Ouh,Lwin Khin Shar,Hong Jin Kang,David Lo*

Main category: cs.SE

TL;DR: 论文提出了一种更现实的评估设置（RDS）来测试问题-提交链接工具的性能，发现现有方法在真实场景中表现下降。基于此，作者提出了EasyLink，结合向量数据库和大型语言模型，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有问题-提交链接工具的评估忽略了真实场景中大量无关提交的干扰，导致性能被高估。

Method: 提出Realistic Distribution Setting（RDS）构建更真实的评估数据集，并开发EasyLink，结合向量数据库和大型语言模型进行重新排序。

Result: 在RDS下，现有深度学习方法的性能下降超过一半，而EasyLink的Precision@1达到75.91%，比现有最优方法提升四倍。

Conclusion: 论文强调了真实评估的重要性，并提出了性能显著提升的EasyLink方法，为问题-提交链接研究提供了实用指导。

Abstract: Issue-commit linking, which connects issues with commits that fix them, is
crucial for software maintenance. Existing approaches have shown promise in
automatically recovering these links. Evaluations of these techniques assess
their ability to identify genuine links from plausible but false links.
However, these evaluations overlook the fact that, in reality, when a
repository has more commits, the presence of more plausible yet unrelated
commits may interfere with the tool in differentiating the correct fix commits.
To address this, we propose the Realistic Distribution Setting (RDS) and use it
to construct a more realistic evaluation dataset that includes 20 open-source
projects. By evaluating tools on this dataset, we observe that the performance
of the state-of-the-art deep learning-based approach drops by more than half,
while the traditional Information Retrieval method, VSM, outperforms it.
  Inspired by these observations, we propose EasyLink, which utilizes a vector
database as a modern Information Retrieval technique. To address the
long-standing problem of the semantic gap between issues and commits, EasyLink
leverages a large language model to rerank the commits retrieved from the
database. Under our evaluation, EasyLink achieves an average Precision@1 of
75.91%, improving over the state-of-the-art by over four times. Additionally,
this paper provides practical guidelines for advancing research in issue-commit
link recovery.

</details>


### [12] [Explainability as a Compliance Requirement: What Regulated Industries Need from AI Tools for Design Artifact Generation](https://arxiv.org/abs/2507.09220)
*Syed Tauhid Ullah Shah,Mohammad Hussein,Ann Barcomb,Mohammad Moshirpour*

Main category: cs.SE

TL;DR: 论文探讨了AI工具在需求工程中生成设计工件时的可解释性差距，通过访谈揭示了非解释性AI输出带来的问题，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 研究AI工具在需求工程中的应用，特别是在受监管行业中，透明度和可追溯性至关重要，但现有工具缺乏可解释性。

Method: 通过半结构化访谈，调查了十位来自安全关键行业的从业者，探讨AI工具的集成、挑战及缓解策略。

Result: 发现非解释性AI输出导致手动验证增加、信任降低、领域术语处理困难、团队协作受阻和合规风险。

Conclusion: 提出了改进方向，如源追踪、决策解释、领域适应和合规验证，以提高AI工具的透明度和可靠性。

Abstract: Artificial Intelligence (AI) tools for automating design artifact generation
are increasingly used in Requirements Engineering (RE) to transform textual
requirements into structured diagrams and models. While these AI tools,
particularly those based on Natural Language Processing (NLP), promise to
improve efficiency, their adoption remains limited in regulated industries
where transparency and traceability are essential. In this paper, we
investigate the explainability gap in AI-driven design artifact generation
through semi-structured interviews with ten practitioners from safety-critical
industries. We examine how current AI-based tools are integrated into workflows
and the challenges arising from their lack of explainability. We also explore
mitigation strategies, their impact on project outcomes, and features needed to
improve usability. Our findings reveal that non-explainable AI outputs
necessitate extensive manual validation, reduce stakeholder trust, struggle to
handle domain-specific terminology, disrupt team collaboration, and introduce
regulatory compliance risks, often negating the anticipated efficiency
benefits. To address these issues, we identify key improvements, including
source tracing, providing clear justifications for tool-generated decisions,
supporting domain-specific adaptation, and enabling compliance validation. This
study outlines a practical roadmap for improving the transparency, reliability,
and applicability of AI tools in requirements engineering workflows,
particularly in regulated and safety-critical environments where explainability
is crucial for adoption and certification.

</details>


### [13] [Enhancing Interpretability in Software Change Management with Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.09315)
*Yongqian Sun,Weihua Kuang,Chao Shen,Xidao Wen,Tinghua Zheng,Heng Liu,Shenglin Zhang,Bo Wu,Dan Pei*

Main category: cs.SE

TL;DR: SCELM是一个端到端的自动化框架，用于高效管理软件变更，减少服务故障和经济损失。


<details>
  <summary>Details</summary>
Motivation: 现代在线服务中频繁的软件变更带来重大风险，需要一种高效的解决方案。

Method: 提出SCELM框架，实现软件变更的自动化评估和生命周期管理。

Result: SCELM显著减少了服务故障和经济损失。

Conclusion: SCELM为软件变更管理提供了一种高效且精确的解决方案。

Abstract: In modern online services, frequent software changes introduce significant
risks. To tackle this challenge, we propose SCELM (Software Change Evaluation
and Lifecycle Management), an end-to-end automated framework for software
change management. SCELM aims to manage software changes efficiently and
precisely, significantly reducing service failures and economic losses.

</details>


### [14] [Enhancing NeuroEvolution-Based Game Testing: A Branch Coverage Approach for Scratch Programs](https://arxiv.org/abs/2507.09414)
*Khizra Sohail,Atif Aftab Ahmed Jilani,Nigar Azhar Butt*

Main category: cs.SE

TL;DR: 论文提出了一种基于分支覆盖的适应度函数，用于改进游戏自动化测试中的测试效果，并通过实验验证其优于传统的语句覆盖方法。


<details>
  <summary>Details</summary>
Motivation: 游戏程序的非确定性和复杂控制结构使得自动化测试生成具有挑战性，而仅依赖语句覆盖无法保证所有逻辑分支的执行，因此需要更有效的测试方法。

Method: 扩展了NEATEST框架，引入分支覆盖适应度函数，优先处理控制依赖分支，以最大化分支探索。实验比较了基于语句覆盖和分支覆盖的两种方法。

Result: 在25个Scratch游戏中，基于分支覆盖的方法在13个游戏中表现更好，尤其在复杂条件结构的程序中，且具有更低的误报率。

Conclusion: 分支覆盖的测试生成方法能显著提高测试覆盖率和故障检测能力，适用于游戏程序的自动化测试。

Abstract: Automated test generation for game-like programs presents unique challenges
due to their non-deterministic behavior and complex control structures. The
NEATEST framework has been used for automated testing in Scratch games,
employing neuroevolution-based test generation optimized for statement
coverage. However, statement coverage alone is often insufficient for fault
detection, as it does not guarantee execution of all logical branches. This
paper introduces a branch coverage-based fitness function to enhance test
effectiveness in automated game testing. We extend NEATEST by integrating a
branch fitness function that prioritizes control-dependent branches, guiding
the neuroevolution process to maximize branch exploration. To evaluate the
effectiveness of this approach, empirical experiments were conducted on 25
Scratch games, comparing Neatest with Statement Coverage (NSC) against Neatest
with Branch Coverage (NBC). A mutation analysis was also performed to assess
the fault detection capabilities of both techniques. The results demonstrate
that NBC achieves higher branch coverage than NSC in 13 out of 25 games,
particularly in programs with complex conditional structures. Moreover, NBC
achieves a lower false positive rate in mutation testing, making it a more
reliable approach for identifying faulty behavior in game programs. These
findings confirm that branch coverage-based test generation improves test
coverage and fault detection in Scratch programs.

</details>


### [15] [Evaluating LLMs on Sequential API Call Through Automated Test Generation](https://arxiv.org/abs/2507.09481)
*Yuheng Huang,Da Song,Zhenlan Ji,Shuai Wang,Lei Ma*

Main category: cs.SE

TL;DR: StateGen是一个自动化框架，用于生成涉及顺序API交互的多样化编码任务，填补了现有基准测试的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试依赖手动收集的测试用例，无法自动检查语义正确性，且忽略了顺序API调用的复杂交互。

Method: StateGen结合状态机约束求解、能量采样和控制流注入生成可执行程序，并通过两个LLM代理将其转化为自然语言任务描述。

Result: 构建了StateEval基准，包含120个已验证测试用例，覆盖三个代表性场景，实验证明StateGen能有效生成具有挑战性的API任务。

Conclusion: StateGen为LLM工具使用的测试和评估提供了新方法，揭示了当前LLM在API集成中的改进空间。

Abstract: By integrating tools from external APIs, Large Language Models (LLMs) have
expanded their promising capabilities in a diverse spectrum of complex
real-world tasks. However, testing, evaluation, and analysis of LLM tool use
remain in their early stages. Most existing benchmarks rely on manually
collected test cases, many of which cannot be automatically checked for
semantic correctness and instead depend on static methods such as string
matching. Additionally, these benchmarks often overlook the complex
interactions that occur between sequential API calls, which are common in
real-world applications. To fill the gap, in this paper, we introduce StateGen,
an automated framework designed to generate diverse coding tasks involving
sequential API interactions. StateGen combines state-machine-based API
constraint solving and validation, energy-based sampling, and control-flow
injection to generate executable programs. These programs are then translated
into human-like natural language task descriptions through a collaboration of
two LLM agents. Utilizing StateGen, we construct StateEval, a benchmark
encompassing 120 verified test cases spanning across three representative
scenarios: Session Service, Tensor Operation, and ElevenLabs MCP. Experimental
results confirm that StateGen can effectively generate challenging and
realistic API-oriented tasks, highlighting areas for improvement in current
LLMs incorporating APIs.

</details>


### [16] [Towards LLM-Based Automatic Playtest](https://arxiv.org/abs/2507.09490)
*Yan Zhao,Chiwei Tang*

Main category: cs.SE

TL;DR: 论文提出了一种基于LLM的自动化游戏测试方法Lap，利用ChatGPT测试三消游戏，通过环境处理、动作生成和执行三阶段实现，并在实验中表现优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 手动游戏测试耗时且昂贵，而传统自动化工具缺乏领域知识和问题解决能力。AI的进步为LLM应用于游戏测试提供了可能，但现有LLM无法视觉感知游戏环境，且多数研究局限于文本游戏或具备API的游戏。

Method: Lap方法包括游戏环境处理、基于提示的动作生成和动作执行三阶段，通过将游戏板转换为数值矩阵，利用ChatGPT生成动作建议并执行，迭代直到超时。

Result: 在开源三消游戏CasseBonbons上的实验表明，Lap在代码覆盖率和触发程序崩溃方面优于现有工具。

Conclusion: Lap展示了LLM在自动化测试中的潜力，为未来自动测试和LLM应用提供了新思路。

Abstract: Playtesting is the process in which people play a video game for testing. It
is critical for the quality assurance of gaming software. Manual playtesting is
time-consuming and expensive. However, automating this process is challenging,
as playtesting typically requires domain knowledge and problem-solving skills
that most conventional testing tools lack. Recent advancements in artificial
intelligence (AI) have opened up new possibilities for applying Large Language
Models (LLMs) to playtesting. However, significant challenges remain: current
LLMs cannot visually perceive game environments, and most existing research
focuses on text-based games or games with robust APIs. Many non-text games lack
APIs to provide textual descriptions of game states, making it almost
impossible to naively apply LLMs for playtesting. This paper introduces Lap,
our novel approach to LLM-based Automatic Playtesting, which uses ChatGPT to
test match-3 games, a category of games where players match three or more
identical tiles in a row or column to earn points. Lap encompasses three key
phases: processing of game environments, prompting-based action generation, and
action execution. Given a match-3 game, Lap takes a snapshot of the game board
and converts it to a numeric matrix. It then prompts the ChatGPT-O1-mini API to
suggest moves based on that matrix and tentatively applies the suggested moves
to earn points and trigger changes in the game board. It repeats the
above-mentioned three steps iteratively until timeout. For evaluation, we
conducted a case study using Lap on an open-source match-3 game, CasseBonbons,
and empirically compared it with three existing tools. Our results are
promising: Lap outperformed existing tools by achieving higher code coverage
and triggering more program crashes. This research sheds light on the future of
automatic testing and LLM applications.

</details>


### [17] [It Only Gets Worse: Revisiting DL-Based Vulnerability Detectors from a Practical Perspective](https://arxiv.org/abs/2507.09529)
*Yunqian Wang,Xiaohong Li,Yao Zhang,Yuekang Li,Zhiping Zhou,Ruitao Feng*

Main category: cs.SE

TL;DR: VulTegra框架对基于深度学习的漏洞检测器进行多维评估，发现现有方法在一致性、实际能力和扩展性方面存在问题，并揭示了预训练模型并非总是优于从头训练的模型。


<details>
  <summary>Details</summary>
Motivation: 随着软件漏洞威胁增加，深度学习检测器流行，但其在CWE范围内的一致性、实际效果和场景适用性存疑，可能导致不可靠检测。

Method: 提出VulTegra框架，对从头训练和预训练的DL模型进行多维比较，分析关键因素对检测性能的影响。

Result: 实验表明，调整关键因素可显著提升召回率和F1分数，预训练模型在特定场景下表现更优。

Conclusion: 研究强调需结合漏洞类型和代码特征改进检测模型设计，并指出CWE分类的局限性。

Abstract: With the growing threat of software vulnerabilities, deep learning (DL)-based
detectors have gained popularity for vulnerability detection. However, doubts
remain regarding their consistency within declared CWE ranges, real-world
effectiveness, and applicability across scenarios. These issues may lead to
unreliable detection, high false positives/negatives, and poor adaptability to
emerging vulnerabilities. A comprehensive analysis is needed to uncover
critical factors affecting detection and guide improvements in model design and
deployment. In this paper, we present VulTegra, a novel evaluation framework
that conducts a multidimensional comparison of scratch-trained and
pre-trained-based DL models for vulnerability detection. VulTegra reveals that
state-of-the-art (SOTA) detectors still suffer from low consistency, limited
real-world capabilities, and scalability challenges. Contrary to common belief,
pre-trained models are not consistently better than scratch-trained models but
exhibit distinct strengths in specific contexts.Importantly, our study exposes
the limitations of relying solely on CWE-based classification and identifies
key factors that significantly affect model performance. Experimental results
show that adjusting just one such factor consistently improves recall across
all seven evaluated detectors, with six also achieving better F1 scores. Our
findings provide deeper insights into model behavior and emphasize the need to
consider both vulnerability types and inherent code features for effective
detection.

</details>


### [18] [A Serverless Architecture for Real-Time Stock Analysis using Large Language Models: An Iterative Development and Debugging Case Study](https://arxiv.org/abs/2507.09583)
*Taniv Ashraf*

Main category: cs.SE

TL;DR: 本文介绍了一个基于Google Gemini API的实时股票分析系统，通过无服务器架构和自动化工具实现低成本高效运行。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型（如Gemini）的潜力，为个人提供低成本、高效的金融数据分析工具。

Method: 系统结合Gemini API进行定性分析，通过GitHub Actions自动化数据处理，并使用静态前端展示结果。

Result: 最终架构实现了近乎零成本运行，展示了个人构建AI金融工具的可行性。

Conclusion: 讨论了LLM在金融分析中的作用、调试方法的重要性，以及人机协作在软件开发中的新范式。

Abstract: The advent of powerful, accessible Large Language Models (LLMs) like Google's
Gemini presents new opportunities for democratizing financial data analysis.
This paper documents the design, implementation, and iterative debugging of a
novel, serverless system for real-time stock analysis. The system leverages the
Gemini API for qualitative assessment, automates data ingestion and processing
via GitHub Actions, and presents the findings through a decoupled, static
frontend. We detail the architectural evolution of the system, from initial
concepts to a robust, event-driven pipeline, highlighting the practical
challenges encountered during deployment. A significant portion of this paper
is dedicated to a case study on the debugging process, covering common software
errors, platform-specific permission issues, and rare, environment-level
platform bugs. The final architecture operates at a near-zero cost,
demonstrating a viable model for individuals to build sophisticated AI-powered
financial tools. The operational application is publicly accessible, and the
complete source code is available for review. We conclude by discussing the
role of LLMs in financial analysis, the importance of robust debugging
methodologies, and the emerging paradigm of human-AI collaboration in software
development.

</details>


### [19] [How to Define Design in Industrial Control and Automation Software](https://arxiv.org/abs/2507.09594)
*Aydin Homay*

Main category: cs.SE

TL;DR: 论文探讨了设计在工程中的重要性，指出缺乏科学基础会导致主观决策，影响效率和创新。研究通过分析软件行业的设计定义，挑战误解，并提出科学定义设计的方法。


<details>
  <summary>Details</summary>
Motivation: 设计在工程中至关重要，但缺乏科学基础导致主观决策，影响效率和创新，尤其在软件和工业控制领域。

Method: 回顾软件行业的设计定义，挑战误解，基于设计理论提出科学定义设计的方法，并区分临时和系统设计方法。

Result: 提出了科学定义设计的方法，并探讨了如何平衡操作和进化需求。

Conclusion: 通过科学定义设计，可以提高设计效率和创新性，尤其在软件和工业控制领域。

Abstract: Design is a fundamental aspect of engineering, enabling the creation of
products, systems, and organizations to meet societal and/or business needs.
However, the absence of a scientific foundation in design often results in
subjective decision-making, reducing both efficiency and innovation. This
challenge is particularly evident in the software industry and, by extension,
in the domain of industrial control and automation systems (iCAS).
  In this study, first we review the existing design definitions within the
software industry, challenge prevailing misconceptions about design, review
design definition in the field of design theory and address key questions such
as: When does design begin? How can design be defined scientifically? What
constitutes good design? and the difference between design and design language
by relying on advancements in the field of design theory. We also evaluate the
distinction between ad-hoc and systematic design approaches, and present
arguments on how to balance complementary operational concerns while resolving
conflicting evolutionary concerns.

</details>


### [20] [The Mythical Good Software](https://arxiv.org/abs/2507.09596)
*Aydin Homay*

Main category: cs.SE

TL;DR: 论文探讨了高内聚低耦合的局限性，指出其可能笨拙、模糊甚至有害，并强调设计时需权衡成本。


<details>
  <summary>Details</summary>
Motivation: 澄清高内聚低耦合的误解，揭示其潜在问题，提醒设计时需综合考虑。

Method: 通过分析和哲学探讨，解释高内聚低耦合的局限性及其实际影响。

Result: 指出高内聚低耦合并非绝对理想，设计需权衡时间和空间成本。

Conclusion: 设计原则应灵活应用，避免盲目追求高内聚低耦合而忽视实际需求。

Abstract: Good software has high cohesion and low coupling is clumsy, obscure, and in
some certain cases could be actually a harmful state of being. It is clumsy
because there is no perfect correlation between higher cohesiveness and optimum
design, and it is obscure because it conveys the message that coupling and
cohesion are two distinct design principles, while there are in principle the
same design approaches, and only the time and space differ between them, and it
could also be a harmful state of being because we should not always aim for
higher cohesiveness without considering its cost.
  In the course of this study, we aim to elucidate for the readers the meaning
and underlying philosophy of the aforementioned paragraph.

</details>


### [21] [Complexity and Coupling: A Functional Domain Approach](https://arxiv.org/abs/2507.09599)
*Aydin Homay*

Main category: cs.SE

TL;DR: 本文为复杂性和耦合提供了基于功能域的精确科学定义，强调现有定义的模糊性，并探讨耦合设计如何增加复杂性及其可能的减少方法。


<details>
  <summary>Details</summary>
Motivation: 解决工业控制和自动化系统中复杂性和耦合定义的模糊性问题，澄清物理属性定义导致的混淆。

Method: 通过多学科（如软件工程、工业自动化、机械设计）的案例分析，重新定义复杂性和耦合。

Result: 复杂性不必然与系统规模或组件数量相关，耦合发生在功能域而非物理域。

Conclusion: 有效设计需在功能域内解决耦合和复杂性问题。

Abstract: This paper provides a precise and scientific definition of complexity and
coupling, grounded in the functional domain, particularly within industrial
control and automation systems (iCAS). We highlight the widespread ambiguity in
defining complexity and coupling, emphasizing that many existing definitions
rooted in physical attributes lead to confusion and inconsistencies.
Furthermore, we re-exhibit why coupled design inherently increases complexity
and how potentially this complexity could be reduced. Drawing on examples from
various disciplines, such as software engineering, industrial automation, and
mechanical design, we demonstrate that complexity does not necessarily
correlate with system size or the number of components, and coupling, unlike
common belief in software engineering, actually does not occur in the physical
domain but in the functional domain. We conclude that effective design
necessitates addressing coupling and complexity within the functional domain.

</details>


### [22] [Code Review as Decision-Making -- Building a Cognitive Model from the Questions Asked During Code Review](https://arxiv.org/abs/2507.09637)
*Lo Gullstrand Heander,Emma Söderberg,Christofer Rydenfält*

Main category: cs.SE

TL;DR: 论文探讨了代码审查的认知过程，提出了CRDM模型，强调代码审查分为两个阶段：定位阶段和分析阶段，以提升效率和保持人际效益。


<details>
  <summary>Details</summary>
Motivation: 尽管代码审查在软件工程中很重要，但现有工具和流程存在挑战，自动化可能牺牲人际效益。研究旨在通过理解认知过程改进工具支持。

Method: 通过民族志有声思维研究，对10名参与者的34次代码审查进行主题、统计、时间和序列分析，构建认知模型。

Result: 提出了CRDM模型，揭示代码审查分为定位阶段和分析阶段，涉及多项决策。

Conclusion: CRDM模型有助于改进代码审查工具和流程，同时保持其人际效益。

Abstract: Code review is a well-established and valued practice in the software
engineering community contributing to both code quality and interpersonal
benefits. However, there are challenges in both tools and processes that give
rise to misalignments and frustrations. Recent research seeks to address this
by automating code review entirely, but we believe that this risks losing the
majority of the interpersonal benefits such as knowledge transfer and shared
ownership.
  We believe that by better understanding the cognitive processes involved in
code review, it would be possible to improve tool support, with out without AI,
and make code review both more efficient, more enjoyable, while increasing or
maintaining all of its benefits. In this paper, we conduct an ethnographic
think-aloud study involving 10 participants and 34 code reviews. We build a
cognitive model of code review bottom up through thematic, statistical,
temporal, and sequential analysis of the transcribed material. Through the
data, the similarities between the cognitive process in code review and
decision-making processes, especially recognition-primed decision-making,
become apparent.
  The result is the Code Review as Decision-Making (CRDM) model that shows how
the developers move through two phases during the code review; first an
orientation phase to establish context and rationale and then an analytical
phase to understand, assess, and plan the rest of the review. Throughout the
process several decisions must be taken, on writing comments, finding more
information, voting, running the code locally, verifying continuous integration
results, etc.
  Analysis software and process-coded data publicly available at:
https://doi.org/10.5281/zenodo.15758266

</details>


### [23] [Is Quantization a Deal-breaker? Empirical Insights from Large Code Models](https://arxiv.org/abs/2507.09665)
*Saima Afrin,Bowen Xu,Antonio Mastropaolo*

Main category: cs.SE

TL;DR: 论文研究了量化技术对大型代码模型生成代码质量的影响，发现量化不仅能保持功能正确性，还能保留代码的可维护性和结构简洁性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的资源需求和碳足迹问题日益突出，量化技术虽能减少资源需求，但现有研究仅关注功能正确性，忽略了代码质量的其他关键方面。

Method: 采用激活感知权重量化（AWQ）技术对CodeLlama和DeepSeekCoder模型进行量化，生成Java和Python代码，并使用静态分析工具评估代码质量指标。

Result: 量化技术不仅保持了功能正确性，还保留了代码的可维护性和结构简洁性等关键质量属性。

Conclusion: 量化是一种稳健的技术，适用于优化大型代码模型，同时保持代码质量。

Abstract: The growing scale of large language models (LLMs) not only demands extensive
computational resources but also raises environmental concerns due to their
increasing carbon footprint. Model quantization emerges as an effective
approach that can reduce the resource demands of LLMs by decreasing parameter
precision without substantially affecting performance (e.g., 16 bit to 4 bit).
While recent studies have established quantization as a promising approach for
optimizing large code models (LCMs), a specialized subset of LLMs tailored for
automated software engineering, their findings offer only limited insights into
its practical implications. Specifically, current investigations focus only on
the functional correctness of the code generated by quantized models,
neglecting how quantization impacts critical aspects of code quality such as
reliability, maintainability, and security. To bridge this gap, our study
investigates the effects of quantization on the qualitative aspects of
automatically generated code. We apply Activation-aware Weight Quantization
(AWQ) to two widely used code models, CodeLlama and DeepSeekCoder, to generate
Java and Python code. Using state-of-the-art static analysis tools, we evaluate
software quality metrics and static features including cyclomatic complexity,
cognitive complexity, and lines of code. Our findings reveal that quantization
is a robust technique that not only preserves functional correctness, but also
retains key qualitative code attributes sought after by developers, such as
maintainability and structural simplicity.

</details>


### [24] [OrQstrator: An AI-Powered Framework for Advanced Quantum Circuit Optimization](https://arxiv.org/abs/2507.09682)
*Laura Baird,Armin Moin*

Main category: cs.SE

TL;DR: OrQstrator是一个基于深度强化学习的模块化框架，用于在NISQ时代优化量子电路。它通过智能选择三种互补的优化器，输出适应硬件约束的优化电路。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，量子电路的优化面临噪声和规模限制的挑战，需要一种智能、高效的优化方法。

Method: 框架包含三个优化模块：基于DRL的电路重写器、领域特定优化器和参数化电路实例化器，通过中央协调引擎根据电路结构和硬件约束选择优化策略。

Result: 系统输出优化的量子电路，适应硬件约束，提升门数量、深度和保真度等性能指标。

Conclusion: OrQstrator通过模块化和智能协调，为NISQ时代的量子电路优化提供了高效解决方案。

Abstract: We propose a novel approach, OrQstrator, which is a modular framework for
conducting quantum circuit optimization in the Noisy Intermediate-Scale Quantum
(NISQ) era. Our framework is powered by Deep Reinforcement Learning (DRL). Our
orchestration engine intelligently selects among three complementary circuit
optimizers: A DRL-based circuit rewriter trained to reduce depth and gate count
via learned rewrite sequences; a domain-specific optimizer that performs
efficient local gate resynthesis and numeric optimization; a parameterized
circuit instantiator that improves compilation by optimizing template circuits
during gate set translation. These modules are coordinated by a central
orchestration engine that learns coordination policies based on circuit
structure, hardware constraints, and backend-aware performance features such as
gate count, depth, and expected fidelity. The system outputs an optimized
circuit for hardware-aware transpilation and execution, leveraging techniques
from an existing state-of-the-art approach, called the NISQ Analyzer, to adapt
to backend constraints.

</details>


### [25] [Prompting for Performance: Exploring LLMs for Configuring Software](https://arxiv.org/abs/2507.09790)
*Helge Spieker,Théo Matricon,Nassim Belmecheri,Jørn Eirik Betten,Gauthier Le Bartz Lyan,Heraldo Borges,Quentin Mazouni,Dennis Gross,Arnaud Gotlieb,Mathieu Acher*

Main category: cs.SE

TL;DR: 论文探讨了大型语言模型（LLMs）在性能导向的软件配置中的潜力，初步结果显示其能力与局限性并存。


<details>
  <summary>Details</summary>
Motivation: 软件配置选项繁多且影响性能，传统机器学习方法计算成本高，研究探索LLMs是否能辅助配置决策。

Method: 通过提示评估LLMs在识别选项、排序配置和推荐高性能配置等任务中的表现，涵盖编译器、视频编码器等系统。

Result: LLMs在某些任务和系统中表现与专家知识一致，但也存在幻觉或浅层推理的问题。

Conclusion: 研究为LLMs在软件配置中的系统评估和解决方案设计提供了初步探索。

Abstract: Software systems usually provide numerous configuration options that can
affect performance metrics such as execution time, memory usage, binary size,
or bitrate. On the one hand, making informed decisions is challenging and
requires domain expertise in options and their combinations. On the other hand,
machine learning techniques can search vast configuration spaces, but with a
high computational cost, since concrete executions of numerous configurations
are required. In this exploratory study, we investigate whether large language
models (LLMs) can assist in performance-oriented software configuration through
prompts. We evaluate several LLMs on tasks including identifying relevant
options, ranking configurations, and recommending performant configurations
across various configurable systems, such as compilers, video encoders, and SAT
solvers. Our preliminary results reveal both positive abilities and notable
limitations: depending on the task and systems, LLMs can well align with expert
knowledge, whereas hallucinations or superficial reasoning can emerge in other
cases. These findings represent a first step toward systematic evaluations and
the design of LLM-based solutions to assist with software configuration.

</details>


### [26] [Measuring What Matters: A Framework for Evaluating Safety Risks in Real-World LLM Applications](https://arxiv.org/abs/2507.09820)
*Jia Yi Goh,Shaun Khoo,Nyx Iskandar,Gabriel Chua,Leanne Tan,Jessica Foo*

Main category: cs.SE

TL;DR: 提出一个评估LLM应用级安全性的实用框架，包括定制安全风险分类原则和评估实践，并通过实际部署验证。


<details>
  <summary>Details</summary>
Motivation: 当前安全测试主要关注基础模型，但应用级组件（如系统提示、检索管道等）对整体安全性影响显著，需针对性评估。

Method: 框架分为两部分：1) 定制安全风险分类原则；2) 评估LLM应用安全风险的实践。通过实际部署验证。

Result: 框架在多个用例中验证，为组织扩展安全测试提供参考。

Conclusion: 该框架填补了AI安全理论与实际部署间的差距，为安全且可扩展的LLM应用提供实用指导。

Abstract: Most safety testing efforts for large language models (LLMs) today focus on
evaluating foundation models. However, there is a growing need to evaluate
safety at the application level, as components such as system prompts,
retrieval pipelines, and guardrails introduce additional factors that
significantly influence the overall safety of LLM applications. In this paper,
we introduce a practical framework for evaluating application-level safety in
LLM systems, validated through real-world deployment across multiple use cases
within our organization. The framework consists of two parts: (1) principles
for developing customized safety risk taxonomies, and (2) practices for
evaluating safety risks in LLM applications. We illustrate how the proposed
framework was applied in our internal pilot, providing a reference point for
organizations seeking to scale their safety testing efforts. This work aims to
bridge the gap between theoretical concepts in AI safety and the operational
realities of safeguarding LLM applications in practice, offering actionable
guidance for safe and scalable deployment.

</details>


### [27] [Turning the Tide: Repository-based Code Reflection](https://arxiv.org/abs/2507.09866)
*Wei Zhang,Jian Yang,Jiaxi Yang,Ya Wang,Zhoujun Li,Zeyu Cui,Binyuan Hui,Junyang Lin*

Main category: cs.SE

TL;DR: 论文介绍了LiveRepoReflection，一个用于评估多文件仓库环境中代码理解和生成的基准测试，并提出了RepoReflection-Instruct数据集和RepoReflectionCoder模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽略了代码仓库修改场景，且动态基准测试中存在数据污染和反思能力提升的挑战。

Method: 创建了包含1,888个测试用例的LiveRepoReflection基准测试，并基于多源数据构建了RepoReflection-Instruct数据集，通过两轮对话训练RepoReflectionCoder模型。

Result: 评估了40多个LLM，展示了模型在仓库代码反思任务中的性能。

Conclusion: LiveRepoReflection为代码理解和生成提供了更具挑战性的评估场景，RepoReflectionCoder模型通过指令调优提升了性能。

Abstract: Code large language models (LLMs) enhance programming by understanding and
generating code across languages, offering intelligent feedback, bug detection,
and code updates through reflection, improving development efficiency and
accessibility. While benchmarks (e.g. HumanEval/LiveCodeBench) evaluate code
generation and real-world relevance, previous works ignore the scenario of
modifying code in repositories. Considering challenges remaining in improving
reflection capabilities and avoiding data contamination in dynamic benchmarks,
we introduce LiveRepoReflection, a challenging benchmark for evaluating code
understanding and generation in multi-file repository contexts, featuring 1,888
rigorously filtered test cases across $6$ programming languages to ensure
diversity, correctness, and high difficulty. Further, we create
RepoReflection-Instruct, a large-scale, quality-filtered instruction-tuning
dataset derived from diverse sources, used to train RepoReflectionCoder through
a two-turn dialogue process involving code generation and error-driven repair.
The leaderboard evaluates over 40 LLMs to reflect the model performance of
repository-based code reflection.

</details>


### [28] [PathFuzzing: Worst Case Analysis by Fuzzing Symbolic-Execution Paths](https://arxiv.org/abs/2507.09892)
*Zimu Chen,Di Wang*

Main category: cs.SE

TL;DR: PathFuzzing结合模糊测试和符号执行的优点，提出了一种新的最坏情况分析方法，通过将程序转换为符号程序并应用进化模糊测试技术，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 解决模糊测试中代码覆盖率低和符号执行中路径爆炸的问题，以更有效地进行最坏情况分析。

Method: 将程序转换为符号程序，利用二进制字符串编码执行路径，并通过进化模糊测试技术搜索高资源消耗的路径。

Result: 实验结果表明，PathFuzzing在性能上优于传统的模糊测试和符号执行基线方法。

Conclusion: PathFuzzing是一种有效的WCA方法，结合了两种技术的优势，显著提升了分析效果。

Abstract: Estimating worst-case resource consumption is a critical task in software
development. The worst-case analysis (WCA) problem is an optimization-based
abstraction of this task. Fuzzing and symbolic execution are widely used
techniques for addressing the WCA problem. However, improving code coverage in
fuzzing or managing path explosion in symbolic execution within the context of
WCA poses significant challenges. In this paper, we propose PathFuzzing, aiming
to combine the strengths of both techniques to design a WCA method. The key
idea is to transform a program into a symbolic one that takes an execution path
(encoded as a binary string) and interprets the bits as branch decisions.
PathFuzzing then applies evolutionary fuzzing techniques to the transformed
program to search for binary strings that represent satisfiable path conditions
and lead to high resource consumption. We evaluate the performance of
PathFuzzing experimentally on a benchmark suite that consists of prior work's
benchmarks and some added by us. Results show that PathFuzzing generally
outperforms a fuzzing and a symbolic-execution baseline.

</details>


### [29] [Modelling Interrelations Between Agile Practices: The Agile Map](https://arxiv.org/abs/2507.09907)
*Thomas Hansper,Kevin Phong Pham,Michael Neumann*

Main category: cs.SE

TL;DR: 论文提出了Agile Map模型，用于系统描述敏捷实践间的相互关系，帮助从业者合理选择和组合敏捷实践。


<details>
  <summary>Details</summary>
Motivation: 敏捷实践在应用中存在高度多样性，但其相互关系不明确，导致组合使用时效果受限。

Method: 研究通过系统方法识别敏捷实践间的相互关系，并构建Agile Map理论模型。

Result: Agile Map模型为从业者提供了敏捷实践间关系的系统概述。

Conclusion: Agile Map模型有助于解决敏捷实践组合使用的挑战，提升实践效果。

Abstract: Agile methods are defined through guidelines comprising various practices
intended to enable agile ways of working. These guidelines further comprise a
specific set of agile practices aiming to enable teams for an agile way of
working. However, due to its wide-spread use in practice we know that agile
practices are adopted and tailored intensively, which lead to a high variety of
agile practices in terms of their level of detail. Problem: A high variety of
agile practices can be challenging as we do not know how different agile
practices are interrelated with each other. To be more precise, tailoring and
adopting agile practices may lead to the challenge, that the combinatorial use
of several agile practices can only be successful to a limited extent, as
practices support or even require each other for a effective use in practice.
Objective: Our study aims to provide an enabler for this problem. We want to
identify interrelations between agile practices and describe them in a
systematic manner. Contribution: The core contribution of this paper is the
Agile Map, a theoretical model describing relations between agile practices
following a systematic approach aiming to provide an overview of coherences
between agile practices. The model aims to support practitioners in selecting
and combining agile practices in a meaningful way.

</details>


### [30] [When Less is More: A systematic review of four-day workweek conceptualizations and their effects on organizational performance](https://arxiv.org/abs/2507.09911)
*Marvin Auf der Landwehr,Julia Topp,Michael Neumann*

Main category: cs.SE

TL;DR: 研究探讨了压缩工作制（如四天工作周）对IT企业运营效率的影响，并提出了一个综合框架。


<details>
  <summary>Details</summary>
Motivation: 敏捷IT组织需要高效灵活的工作环境，压缩工作制可能带来多种益处。

Method: 通过系统文献综述和网络内容分析，研究压缩工作制的概念及其组织和社会影响。

Result: 提出了一个元框架，指导根据管理前提和情境采用压缩工作制。

Conclusion: 压缩工作制对IT企业运营效率有积极影响，需结合具体情况实施。

Abstract: Context: Agile IT organizations, which are characterized by self-organization
and collaborative social interactions, require motivating, efficient and
flexible work environments to maximize value creation. Compressed work
schedules such as the four-day workweek have evolved into multiple facets over
the last decades and are associated with various benefits for organizations and
their employees. Objective: Our objective in this study is to deepen our
comprehension of the impact of compressed work schedules on the operational
efficacy of IT enterprises, while concurrently developing a comprehensive
framework delineating the intricacies of compressed work schedules.Method: We
conducted a systematic review of available conceptualizations related to
four-day workweek schedules and elaborate on their organizational and social
effects. To cover scientific and practice-oriented literature, our review
combined a systematic literature review and a web content analysis. Results:
Based on the generated insights, we derive a meta-framework that matches
conceptualizations and effects, finally guiding the adoption of compressed work
schedules based on individual managerial prerequisites and circumstances.

</details>


### [31] [Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks](https://arxiv.org/abs/2507.10054)
*Emir Bosnak,Sahand Moslemi,Mayasah Lami,Anil Koyuncu*

Main category: cs.SE

TL;DR: 研究探讨开源大语言模型（LLM）在直接或间接提示下生成不安全代码的行为，发现模型常生成漏洞代码，用户角色和提示方式影响结果。


<details>
  <summary>Details</summary>
Motivation: 理解开源LLM在明确要求生成不安全代码时的行为，填补现有研究对直接威胁场景的空白。

Method: 采用动态提示和反向提示两种实验设计，评估三种开源模型生成漏洞代码的能力。

Result: 所有模型常生成漏洞代码，Qwen2正确率最高；用户角色（学生更易成功）和提示方式（直接提示稍优）显著影响结果。

Conclusion: 开源模型的安全机制存在局限，尤其在看似无害的教育请求中。

Abstract: Large Language Models (LLMs) are increasingly used as code assistants, yet
their behavior when explicitly asked to generate insecure code remains poorly
understood. While prior research has focused on unintended vulnerabilities or
adversarial prompting techniques, this study examines a more direct threat
scenario: open-source LLMs generating vulnerable code when prompted either
directly or indirectly. We propose a dual experimental design: (1) Dynamic
Prompting, which systematically varies vulnerability type, user persona, and
directness across structured templates; and (2) Reverse Prompting, which
derives prompts from real vulnerable code samples to assess vulnerability
reproduction accuracy. We evaluate three open-source 7B-parameter models
(Qwen2, Mistral, and Gemma) using ESBMC static analysis to assess both the
presence of vulnerabilities and the correctness of the generated vulnerability
type. Results show all models frequently produce vulnerable outputs, with Qwen2
achieving highest correctness rates. User persona significantly affects
success, where student personas achieved higher vulnerability rates than
professional roles, while direct prompts were marginally more effective.
Vulnerability reproduction followed an inverted-U pattern with cyclomatic
complexity, peaking at moderate ranges. Our findings expose limitations of
safety mechanisms in open-source models, particularly for seemingly benign
educational requests.

</details>


### [32] [LLMShot: Reducing snapshot testing maintenance via LLMs](https://arxiv.org/abs/2507.10062)
*Ergün Batuhan Kaynak,Mayasah Lami,Sahand Moslemi,Anil Koyuncu*

Main category: cs.SE

TL;DR: LLMShot利用视觉大语言模型自动分析快照测试失败，通过分层分类UI变化，显著减少手动检查工作。


<details>
  <summary>Details</summary>
Motivation: 快照测试在UI验证中至关重要，但频繁的UI变更导致测试失败需要手动区分回归和设计变更，维护成本高。

Method: 提出LLMShot框架，利用视觉大语言模型进行分层分类，评估使用Gemma3模型和iOS应用数据集。

Result: 12B模型召回率达84%，4B模型适合持续集成环境，但选择性忽略机制仍有局限。

Conclusion: LLMShot是首个自动化语义快照测试分析方法，显著减少手动工作量，推动智能UI测试发展。

Abstract: Snapshot testing has emerged as a critical technique for UI validation in
modern software development, yet it suffers from substantial maintenance
overhead due to frequent UI changes causing test failures that require manual
inspection to distinguish between genuine regressions and intentional design
changes. This manual triage process becomes increasingly burdensome as
applications evolve, creating a need for automated analysis solutions. This
paper introduces LLMShot, a novel framework that leverages vision-based Large
Language Models to automatically analyze snapshot test failures through
hierarchical classification of UI changes. To evaluate LLMShot's effectiveness,
we developed a comprehensive dataset using a feature-rich iOS application with
configurable feature flags, creating realistic scenarios that produce authentic
snapshot differences representative of real development workflows. Our
evaluation using Gemma3 models demonstrates strong classification performance,
with the 12B variant achieving over 84% recall in identifying failure root
causes while the 4B model offers practical deployment advantages with
acceptable performance for continuous integration environments. However, our
exploration of selective ignore mechanisms revealed significant limitations in
current prompting-based approaches for controllable visual reasoning. LLMShot
represents the first automated approach to semantic snapshot test analysis,
offering developers structured insights that can substantially reduce manual
triage effort and advance toward more intelligent UI testing paradigms.

</details>


### [33] [Accelerating Automatic Program Repair with Dual Retrieval-Augmented Fine-Tuning and Patch Generation on Large Language Models](https://arxiv.org/abs/2507.10103)
*Hanyang Guo,Xiaoheng Xie,Hong-Ning Dai,Peng Di,Yu Zhang,Bishenghui Tao,Zibin Zheng*

Main category: cs.SE

TL;DR: SelRepair是一种结合微调LLM和双RAG模块的新型APR方法，显著提升了程序修复性能并减少了推理时间。


<details>
  <summary>Details</summary>
Motivation: 现有APR方法受限于缺陷类型、训练数据质量和模型参数规模，且当前LLM和RAG设计未充分考虑代码修复任务和代码特性。

Method: 通过微调LLM并结合语义和语法/结构相似性信息的双RAG模块，利用bug-fix对数据集进行优化。

Result: 在Java数据集上，SelRepair的精确匹配率分别达到26.29%和17.64%，推理时间减少至少6.42%。

Conclusion: SelRepair通过创新的设计和优化，显著提升了APR任务的性能和效率。

Abstract: Automated Program Repair (APR) is essential for ensuring software reliability
and quality while enhancing efficiency and reducing developers' workload.
Although rule-based and learning-based APR methods have demonstrated their
effectiveness, their performance was constrained by the defect type of repair,
the quality of training data, and the size of model parameters. Recently, Large
Language Models (LLMs) combined with Retrieval-Augmented-Generation (RAG) have
been increasingly adopted in APR tasks. However, current code LLMs and RAG
designs neither fully address code repair tasks nor consider code-specific
features. To overcome these limitations, we propose SelRepair, a novel APR
approach with integration of a fine-tuned LLM with a newly-designed dual RAG
module. This approach uses a bug-fix pair dataset for fine-tuning and
incorporates semantic and syntactic/structural similarity information through
an RAG selection gate. This design ensures relevant information is retrieved
efficiently, thereby reducing token length and inference time. Evaluations on
Java datasets show SelRepair outperforms other APR methods, achieving 26.29%
and 17.64% in terms of exact match (EM) on different datasets while reducing
inference time by at least 6.42% with controlled input lengths.

</details>


### [34] [Breaking the Myth: Can Small Models Infer Postconditions Too?](https://arxiv.org/abs/2507.10182)
*Gehao Zhang,Zhenting Wang,Juan Zhai*

Main category: cs.SE

TL;DR: 研究表明，小型、经过微调的语言模型在生成高质量后置条件时，可以显著降低计算成本，效果媲美或优于大型模型。


<details>
  <summary>Details</summary>
Motivation: 手动编写形式化规范既繁琐又容易出错，而大型语言模型（LLMs）虽然能生成规范，但其庞大的模型尺寸和高计算需求引发了对效率的质疑。

Method: 构建了一个包含提示、推理日志和后置条件的专用数据集，并对一个70亿参数的代码模型进行监督微调，解决了现实仓库依赖性和预状态信息保留问题。

Result: 在真实Java缺陷基准测试（Defects4J）中，该小型模型在语法正确性、语义正确性和缺陷区分能力上媲美或优于大型模型。

Conclusion: 针对特定任务的微调可以让小型模型达到大型模型的效果，为自动化规范生成提供了实用且高效的解决方案。

Abstract: Formal specifications are essential for ensuring software correctness, yet
manually writing them is tedious and error-prone. Large Language Models (LLMs)
have shown promise in generating such specifications from natural language
intents, but the giant model size and high computational demands raise a
fundamental question: Do we really need large models for this task? In this
paper, we show that a small, fine-tuned language model can achieve high-quality
postcondition generation with much lower computational costs. We construct a
specialized dataset of prompts, reasoning logs, and postconditions, then
supervise the fine-tuning of a $7$B-parameter code model. Our approach tackles
real-world repository dependencies and preserves pre-state information,
allowing for expressive and accurate specifications. We evaluate the model on a
benchmark of real-world Java bugs (Defects4J) and compare against both
proprietary giants (e.g., GPT-4o) and open-source large models. Empirical
results demonstrate that our compact model matches or outperforms significantly
larger counterparts in syntax correctness, semantic correctness, and
bug-distinguishing capability. These findings highlight that targeted
fine-tuning on a modest dataset can enable small models to achieve results
formerly seen only in massive, resource-heavy LLMs, offering a practical and
efficient path for the real-world adoption of automated specification
generation.

</details>


### [35] [Towards a Framework for Operationalizing the Specification of Trustworthy AI Requirements](https://arxiv.org/abs/2507.10228)
*Hugo Villamizar,Daniel Mendez,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 论文提出整合AMDiRE和PerSpecML两种方法，以解决AI系统可信度问题，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: AI系统的可信度问题日益突出，需要结构化方法来解决上下文依赖的复杂需求。

Method: 结合AMDiRE（基于工件的RE方法）和PerSpecML（基于视角的ML系统需求方法），以支持需求获取和分析。

Result: 提出了一种整合方法，旨在弥合利益相关者关注点与结构化工件模型之间的差距。

Conclusion: 论文总结了关键研究方向和开放挑战，呼吁RE社区进一步探讨。

Abstract: Growing concerns around the trustworthiness of AI-enabled systems highlight
the role of requirements engineering (RE) in addressing emergent,
context-dependent properties that are difficult to specify without structured
approaches. In this short vision paper, we propose the integration of two
complementary approaches: AMDiRE, an artefact-based approach for RE, and
PerSpecML, a perspective-based method designed to support the elicitation,
analysis, and specification of machine learning (ML)-enabled systems. AMDiRE
provides a structured, artefact-centric, process-agnostic methodology and
templates that promote consistency and traceability in the results; however, it
is primarily oriented toward deterministic systems. PerSpecML, in turn,
introduces multi-perspective guidance to uncover concerns arising from the
data-driven and non-deterministic behavior of ML-enabled systems. We envision a
pathway to operationalize trustworthiness-related requirements, bridging
stakeholder-driven concerns and structured artefact models. We conclude by
outlining key research directions and open challenges to be discussed with the
RE community.

</details>


### [36] [An Empirical Study of Interaction Bugs in ROS-based Software](https://arxiv.org/abs/2507.10235)
*Zhixiang Chen,Zhuangbin Chen,Xingjie Cai,Wei Li,Zibin Zheng*

Main category: cs.SE

TL;DR: 论文研究了机器人系统中组件间交互故障（iBugs），分析了121个ROS项目中的iBugs，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 机器人系统的可靠性不仅依赖单个组件的正确性，还依赖组件间交互的正确性，但交互故障（iBugs）研究不足。

Method: 对十个ROS项目中的121个iBugs进行实证研究，分类为三类（系统内、硬件、环境），分析原因和修复策略。

Result: 揭示了iBugs的根源和影响，提出了预防和检测的方向。

Conclusion: 研究结果为设计更健壮和安全的机器人系统提供了参考。

Abstract: Modern robotic systems integrate multiple independent software and hardware
components, each responsible for distinct functionalities such as perception,
decision-making, and execution. These components interact extensively to
accomplish complex end-to-end tasks. As a result, the overall system
reliability depends not only on the correctness of individual components, but
also on the correctness of their interactions. Failures often manifest at the
boundaries between components, yet interaction-related reliability issues in
robotics--referred to here as interaction bugs (iBugs)--remain underexplored.
  This work presents an empirical study of iBugs within robotic systems built
using the Robot Operating System (ROS), a widely adopted open-source robotics
framework. A total of 121 iBugs were analyzed across ten actively maintained
and representative ROS projects. The identified iBugs are categorized into
three major types: intra-system iBugs, hardware iBugs, and environmental iBugs,
covering a broad range of interaction scenarios in robotics. The analysis
includes an examination of root causes, fixing strategies, and the impact of
these bugs. Several findingsa are derived that shed light on the nature of
iBugs and suggest directions for improving their prevention and detection.
These insights aim to inform the design of more robust and safer robotic
systems.

</details>


### [37] [Helveg: Diagrams for Software Documentation](https://arxiv.org/abs/2507.10244)
*Adam Štěpánek,David Kuťák,Barbora Kozlíková,Jan Byška*

Main category: cs.SE

TL;DR: 论文提出了一种改进的API文档可视化工具Helveg，通过交互式图表帮助开发者理解代码库，解决了传统文档的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统文本形式的文档不适合代码库的高层次探索分析，因其固定路径限制了用户灵活性。

Method: 设计了一种交互式节点链接图，支持灵活过滤和细节展示，并改进了工具的可读性和用户体验。

Result: 用户测试证实了工具潜力，但也揭示了可读性和用户体验问题，后续版本进行了改进。

Conclusion: 改进后的Helveg工具通过重新设计用户界面和交互方式，显著提升了代码库探索的效率和体验。

Abstract: Software developers often have to gain an understanding of a codebase. Be it
programmers getting onboarded onto a team project or, for example, developers
striving to grasp an external open-source library. In either case, they
frequently turn to the project's documentation. However, documentation in its
traditional textual form is ill-suited for this kind of high-level exploratory
analysis, since it is immutable from the readers' perspective and thus forces
them to follow a predefined path. We have designed an approach bringing aspects
of software architecture visualization to API reference documentation. It
utilizes a highly interactive node-link diagram with expressive node glyphs and
flexible filtering capabilities, providing a high-level overview of the
codebase as well as details on demand. To test our design, we have implemented
a prototype named Helveg, capable of automatically generating diagrams of C\#
codebases. User testing of Helveg confirmed its potential, but it also revealed
problems with the readability, intuitiveness, and user experience of our tool.
Therefore, in this paper, which is an extended version of our VISSOFT paper
with DOI 10.1109/VISSOFT64034.2024.00012, we address many of these problems
through major changes to the glyph design, means of interaction, and user
interface of the tool. To assess the improvements, this new version of Helveg
was evaluated again with the same group of participants as the previous
version.

</details>


### [38] [A Grounded Theory on the Teacher and Student Roles in Pair Programming](https://arxiv.org/abs/2507.10305)
*Linus Ververs,Trang Linh Lam,Janina Berger,Lutz Prechelt*

Main category: cs.SE

TL;DR: 研究探讨了知识转移在结对编程中的负面影响，提出了“权力差距”理论，并指出忽视伙伴需求可能导致防御行为。


<details>
  <summary>Details</summary>
Motivation: 理解知识转移在何种情况下会损害结对编程的效果。

Method: 基于17次结对编程记录和6次访谈，采用扎根理论方法。

Result: 定义了学生和教师角色，提出了权力差距理论，并描述了避免的陷阱。

Conclusion: 忽视权力差距和伙伴需求可能导致防御行为，负面影响知识转移、协作和代码质量。

Abstract: Context: Pair programming is an established (agile) practice and is practiced
throughout the industry. Objective: Understand under what circumstances
knowledge transfer can harm a pair programming session. Method: Grounded Theory
Methodology based on 17 recorded pair programming sessions with 18 developers
from 5 German software companies accompanied, by 6 interviews with different
developers from 4 other German companies. Results: We define the student and
teacher roles to help developers deal with a one-sided knowledge gap. We
describe pitfalls to avoid and develop a grounded theory centered around the
Power Gap in pair programming. Conclusions: Knowledge transfer can be harmful
when developers don't pay attention to their partners needs and desires. If
developers don't pay attention to the Power Gap and keep it in check, Defensive
Behavior may arise that leads to a vicious cycle impacting the knowledge
transfer, the Togetherness and the code quality in a negative way.

</details>


### [39] [Streamlined Airborne Software Development for Large UAVs: From Unified Data Collection to Automated Code Generation](https://arxiv.org/abs/2507.10321)
*Viktor Sinitsyn,Nils Schlautmann,Florian Schwaiger,Florian Holzapfel*

Main category: cs.SE

TL;DR: 本文提出了一种新颖的流程和工具链，旨在优化数字接口和机载软件的开发，通过自动化和灵活性满足设计保证要求。


<details>
  <summary>Details</summary>
Motivation: 航空航天行业的技术进步和创新解决方案带来了新挑战，尤其是数字设备间通信接口的高效处理问题。

Method: 提出了一种自动化且灵活的流程和工具链，用于开发数字接口和机载软件。

Result: 该方法已在多个项目中成功应用。

Conclusion: 该解决方案通过自动化和灵活性，有效解决了数字接口开发的挑战，同时满足设计保证要求。

Abstract: The aerospace industry has experienced significant transformations over the
last decade, driven by technological advancements and innovative solutions in
goods and personal transportation. This evolution has spurred the emergence of
numerous start-ups that now face challenges traditionally encountered by
established aerospace companies. Among these challenges is the efficient
processing of digital intra-device communication interfaces for onboard
equipment - a critical component for ensuring seamless system integration and
functionality. Addressing this challenge requires solutions that emphasize
clear and consistent interface descriptions, automation of processes, and
reduced labor-intensive efforts.
  This paper presents a novel process and toolchain designed to streamline the
development of digital interfaces and onboard software, which our team has
successfully applied in several completed projects. The proposed approach
focuses on automation and flexibility while maintaining compliance with design
assurance requirements.

</details>


### [40] [AssertCoder: LLM-Based Assertion Generation via Multimodal Specification Extraction](https://arxiv.org/abs/2507.10338)
*Enyuan Tian,Yiwei Ci,Qiusong Yang,Yufeng Li,Zhichao Lyu*

Main category: cs.SE

TL;DR: AssertCoder是一个自动化生成高质量SVAs的统一框架，通过多模态硬件设计规范直接生成断言，显著提升功能正确性和突变检测能力。


<details>
  <summary>Details</summary>
Motivation: 手动编写高质量SVAs耗时且易错，AssertCoder旨在填补这一空白。

Method: 采用模态敏感预处理解析多模态规范，通过语义分析器提取结构化表示，利用多步链式思维提示生成断言，并通过基于突变的评估优化断言质量。

Result: 在三个真实RTL设计中，AssertCoder平均提升功能正确性8.4%，突变检测能力5.8%。

Conclusion: AssertCoder显著优于现有方法，为硬件设计验证提供了高效自动化解决方案。

Abstract: Assertion-Based Verification (ABV) is critical for ensuring functional
correctness in modern hardware systems. However, manually writing high-quality
SVAs remains labor-intensive and error-prone. To bridge this gap, we propose
AssertCoder, a novel unified framework that automatically generates
high-quality SVAs directly from multimodal hardware design specifications.
AssertCoder employs a modality-sensitive preprocessing to parse heterogeneous
specification formats (text, tables, diagrams, and formulas), followed by a set
of dedicated semantic analyzers that extract structured representations aligned
with signal-level semantics. These representations are utilized to drive
assertion synthesis via multi-step chain-of-thought (CoT) prompting. The
framework incorporates a mutation-based evaluation approach to assess assertion
quality via model checking and further refine the generated assertions.
Experimental evaluation across three real-world Register-Transfer Level (RTL)
designs demonstrates AssertCoder's superior performance, achieving an average
increase of 8.4% in functional correctness and 5.8% in mutation detection
compared to existing state-of-the-art approaches.

</details>


### [41] [Self-Admitted GenAI Usage in Open-Source Software](https://arxiv.org/abs/2507.10422)
*Tao Xiao,Youmei Fan,Fabio Calefato,Christoph Treude,Raula Gaikovina Kula,Hideaki Hata,Sebastian Baltes*

Main category: cs.SE

TL;DR: 研究通过开发者自我承认使用生成式AI（GenAI）工具的行为，分析了25万个GitHub仓库，揭示了GenAI在开源项目中的任务、内容和目的分类，并探讨了伦理、法律和实践问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具（如GitHub Copilot和ChatGPT）的广泛使用正在改变软件开发，但其实际影响尚不明确。

Method: 通过分析25万个GitHub仓库中的1,292个自我承认使用GenAI的记录，结合定性编码、政策分析和开发者调查。

Result: 开发者积极管理GenAI的使用，未发现GenAI导致代码变更增加的普遍现象。

Conclusion: 研究强调了在AI辅助软件开发中项目级透明度、归属和质量控制的必要性。

Abstract: The widespread adoption of generative AI (GenAI) tools such as GitHub Copilot
and ChatGPT is transforming software development. Since generated source code
is virtually impossible to distinguish from manually written code, their
real-world usage and impact on open-source software development remain poorly
understood. In this paper, we introduce the concept of self-admitted GenAI
usage, that is, developers explicitly referring to the use of GenAI tools for
content creation in software artifacts. Using this concept as a lens to study
how GenAI tools are integrated into open-source software projects, we analyze a
curated sample of more than 250,000 GitHub repositories, identifying 1,292 such
self-admissions across 156 repositories in commit messages, code comments, and
project documentation. Using a mixed methods approach, we derive a taxonomy of
32 tasks, 10 content types, and 11 purposes associated with GenAI usage based
on 284 qualitatively coded mentions. We then analyze 13 documents with policies
and usage guidelines for GenAI tools and conduct a developer survey to uncover
the ethical, legal, and practical concerns behind them. Our findings reveal
that developers actively manage how GenAI is used in their projects,
highlighting the need for project-level transparency, attribution, and quality
control practices in the new era of AI-assisted software development. Finally,
we examine the longitudinal impact of GenAI adoption on code churn in 151
repositories with self-admitted GenAI usage and find no general increase,
contradicting popular narratives on the impact of GenAI on software
development.

</details>
